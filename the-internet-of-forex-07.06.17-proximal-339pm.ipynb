{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "#pd.set_option('display.max_rows', 100)\n",
    "#pd.set_option('display.max_columns', 100)\n",
    "from bokeh.plotting import figure, show, output_file\n",
    "from bokeh.models import ColumnDataSource, Quad\n",
    "from datetime import datetime\n",
    "from math import pi\n",
    "from sklearn.preprocessing import Imputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_curve, auc, recall_score, precision_score\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from time import time\n",
    "t = time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# Keras imports\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Dropout, Activation\n",
    "from keras.layers.convolutional import Convolution2D, MaxPooling2D, Conv1D, MaxPooling1D, AveragePooling1D, UpSampling1D\n",
    "from keras.layers.recurrent import LSTM\n",
    "from keras.layers import Bidirectional, TimeDistributed\n",
    "from keras.callbacks import ReduceLROnPlateau\n",
    "from keras.callbacks import LearningRateScheduler, ModelCheckpoint\n",
    "from keras.optimizers import Adam, RMSprop\n",
    "from keras.utils import np_utils, generic_utils\n",
    "from sklearn.metrics import f1_score\n",
    "from keras.models import Model\n",
    "from keras.models import Sequential\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from keras.constraints import maxnorm\n",
    "from keras import regularizers\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.callbacks import EarlyStopping, Callback, ModelCheckpoint, LearningRateScheduler, ReduceLROnPlateau\n",
    "from keras.layers.advanced_activations import LeakyReLU\n",
    "from weightnorm import data_based_init, AdamWithWeightnorm\n",
    "from keras.utils import np_utils\n",
    "import keras.backend as K\n",
    "from itertools import product\n",
    "from functools import partial\n",
    "from keras.layers.noise import GaussianNoise\n",
    "from keras.layers.advanced_activations import ELU\n",
    "from keras.constraints import maxnorm\n",
    "from numpy.random import seed\n",
    "from sklearn.preprocessing import minmax_scale\n",
    "from keras.optimizers import SGD\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Flatten, Input, merge, add\n",
    "from keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/site-packages/sklearn/cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn import model_selection\n",
    "from sklearn.preprocessing import Imputer\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import log_loss\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import average_precision_score\n",
    "from sklearn import cross_validation\n",
    "from sklearn.model_selection import KFold\n",
    "from matplotlib import pyplot\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import GroupKFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import custom scripts and functions\n",
    "%aimport model_performance_evaluation\n",
    "%aimport custom_metrics\n",
    "%aimport data_processing\n",
    "%aimport make_keras_generators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# !wget https://dl.dropboxusercontent.com/u/53977633/data/df072717611pm.csv\n",
    "# !wget https://dl.dropboxusercontent.com/u/53977633/data/X072717611pm.csv\n",
    "# !wget https://dl.dropboxusercontent.com/u/53977633/data/y072717611pm.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# X = pd.read_csv('/output/X072717611pm.csv')\n",
    "# X.drop(X.columns[0], inplace=True, axis=1)\n",
    "# y = pd.read_csv('/output/y072717611pm.csv')\n",
    "# y.drop(y.columns[0], inplace=True, axis=1)\n",
    "# df_ohlc_and_rectangles = pd.read_csv('/output/df072717611pm.csv')\n",
    "# df_ohlc_and_rectangles.drop(df_ohlc_and_rectangles.columns[0], inplace=True, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing:  EURJPY1440.csv Number  1  of  11\n",
      "We now have: (0, 0) rows of data!\n",
      "Reading in Date, OHLCV, Supply/Demand\n",
      "Renaming df_ohlc column headers for clarity\n",
      "Reading in Rectangle data\n",
      "Renaming df_rects column headers for clarity\n",
      "Identifying supply/demand with supply_or_demand func: EURJPY1440.csv (4950, 12)\n",
      "~~~\n",
      "Identifying zone ends with zone_ender func: EURJPY1440.csv (4950, 14)\n",
      "~~~\n",
      "Your df_norm columns: Index(['O', 'H', 'L', 'C', 'V'], dtype='object')\n",
      "Your df_non_norm columns: Index(['Epoch Date', 'Supply/Demand', 'Object Name', 'Epoch Date Start',\n",
      "       'Epoch Date End', 'Proximal', 'Distal', 'supply_demand',\n",
      "       'rectangle_here', 'Proximal_match_-3_O', 'Proximal_match_-2_O',\n",
      "       'Proximal_match_-1_O', 'Proximal_match_0_O', 'Proximal_match_1_O',\n",
      "       'Proximal_match_2_O', 'Proximal_match_3_O', 'Proximal_match_4_O',\n",
      "       'Proximal_match_5_O', 'Proximal_match_6_O', 'Distal_match_-3_O',\n",
      "       'Distal_match_-2_O', 'Distal_match_-1_O', 'Distal_match_0_O',\n",
      "       'Distal_match_1_O', 'Distal_match_2_O', 'Distal_match_3_O',\n",
      "       'Distal_match_4_O', 'Distal_match_5_O', 'Distal_match_6_O',\n",
      "       'Proximal_match_-3_H', 'Proximal_match_-2_H', 'Proximal_match_-1_H',\n",
      "       'Proximal_match_0_H', 'Proximal_match_1_H', 'Proximal_match_2_H',\n",
      "       'Proximal_match_3_H', 'Proximal_match_4_H', 'Proximal_match_5_H',\n",
      "       'Proximal_match_6_H', 'Distal_match_-3_H', 'Distal_match_-2_H',\n",
      "       'Distal_match_-1_H', 'Distal_match_0_H', 'Distal_match_1_H',\n",
      "       'Distal_match_2_H', 'Distal_match_3_H', 'Distal_match_4_H',\n",
      "       'Distal_match_5_H', 'Distal_match_6_H', 'Proximal_match_-3_L',\n",
      "       'Proximal_match_-2_L', 'Proximal_match_-1_L', 'Proximal_match_0_L',\n",
      "       'Proximal_match_1_L', 'Proximal_match_2_L', 'Proximal_match_3_L',\n",
      "       'Proximal_match_4_L', 'Proximal_match_5_L', 'Proximal_match_6_L',\n",
      "       'Distal_match_-3_L', 'Distal_match_-2_L', 'Distal_match_-1_L',\n",
      "       'Distal_match_0_L', 'Distal_match_1_L', 'Distal_match_2_L',\n",
      "       'Distal_match_3_L', 'Distal_match_4_L', 'Distal_match_5_L',\n",
      "       'Distal_match_6_L', 'Proximal_match_-3_C', 'Proximal_match_-2_C',\n",
      "       'Proximal_match_-1_C', 'Proximal_match_0_C', 'Proximal_match_1_C',\n",
      "       'Proximal_match_2_C', 'Proximal_match_3_C', 'Proximal_match_4_C',\n",
      "       'Proximal_match_5_C', 'Proximal_match_6_C', 'Distal_match_-3_C',\n",
      "       'Distal_match_-2_C', 'Distal_match_-1_C', 'Distal_match_0_C',\n",
      "       'Distal_match_1_C', 'Distal_match_2_C', 'Distal_match_3_C',\n",
      "       'Distal_match_4_C', 'Distal_match_5_C', 'Distal_match_6_C'],\n",
      "      dtype='object')\n",
      "Generating features:  Difference between open and close\n",
      "Shape is now: (4950, 6)\n",
      "~~~\n",
      "Generating features:  Range between high and low\n",
      "Shape is now: (4950, 7)\n",
      "~~~\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/output/data_processing.py:52: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  df_data[\"change_open_close\"] = df_data[\"O\"] - df_data[\"C\"] # add change column, difference between open and close\n",
      "/output/data_processing.py:60: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  df_data[\"range_high_low\"] = df_data[\"H\"] - df_data[\"L\"] # add range, difference between high and low\n",
      "/output/data_processing.py:76: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  df_data[label] =  df_data[each].rolling(window=6).std()\n",
      "/output/data_processing.py:82: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  df_data[label] =  df_data[each].rolling(window=6, center=center).mean()\n",
      "/output/data_processing.py:86: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  df_data['rolling_mean_range_HL'] =  df_data['range_high_low'].rolling(window=6, center=center).mean()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating features:  Generic lagged data\n",
      "Generating features:  Diffs over time for lookforward/lookback range\n",
      "Generating features:  Rolling mean for yesterday, today, tomorrow range\n",
      "Your df_scale_with_PCA: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 'PCA1', 'PCA2', 'PCA3', 'PCA4', 'PCA5', 'PCA6', 'PCA7', 'PCA8', 'PCA9', 'PCA10', 'PCA11', 'PCA12']\n",
      "Your df_scale_with_PCA columns are: ['O', 'H', 'L', 'C', 'V', 'change_open_close', 'range_high_low', 'O_std_dev', 'H_std_dev', 'L_std_dev', 'C_std_dev', 'O_rolling_mean', 'H_rolling_mean', 'L_rolling_mean', 'C_rolling_mean', 'change_open_close_rolling_mean', 'rolling_mean_range_HL', 'lag_-3_O', 'lag_-2_O', 'lag_-1_O', 'lag_0_O', 'lag_1_O', 'lag_2_O', 'lag_3_O', 'lag_4_O', 'lag_5_O', 'lag_6_O', 'lag_-3_H', 'lag_-2_H', 'lag_-1_H', 'lag_0_H', 'lag_1_H', 'lag_2_H', 'lag_3_H', 'lag_4_H', 'lag_5_H', 'lag_6_H', 'lag_-3_L', 'lag_-2_L', 'lag_-1_L', 'lag_0_L', 'lag_1_L', 'lag_2_L', 'lag_3_L', 'lag_4_L', 'lag_5_L', 'lag_6_L', 'lag_-3_C', 'lag_-2_C', 'lag_-1_C', 'lag_0_C', 'lag_1_C', 'lag_2_C', 'lag_3_C', 'lag_4_C', 'lag_5_C', 'lag_6_C', 'O_diff_-3', 'H_diff_-3', 'L_diff_-3', 'C_diff_-3', 'change_open_close_diff_-3', 'O_diff_-2', 'H_diff_-2', 'L_diff_-2', 'C_diff_-2', 'change_open_close_diff_-2', 'O_diff_-1', 'H_diff_-1', 'L_diff_-1', 'C_diff_-1', 'change_open_close_diff_-1', 'O_diff_0', 'H_diff_0', 'L_diff_0', 'C_diff_0', 'change_open_close_diff_0', 'O_diff_1', 'H_diff_1', 'L_diff_1', 'C_diff_1', 'change_open_close_diff_1', 'O_diff_2', 'H_diff_2', 'L_diff_2', 'C_diff_2', 'change_open_close_diff_2', 'O_diff_3', 'H_diff_3', 'L_diff_3', 'C_diff_3', 'change_open_close_diff_3', 'O_diff_4', 'H_diff_4', 'L_diff_4', 'C_diff_4', 'change_open_close_diff_4', 'O_diff_5', 'H_diff_5', 'L_diff_5', 'C_diff_5', 'change_open_close_diff_5', 'O_diff_6', 'H_diff_6', 'L_diff_6', 'C_diff_6', 'change_open_close_diff_6', 'O_rolling_mean_diff_-3', 'H_rolling_mean_diff_-3', 'L_rolling_mean_diff_-3', 'C_rolling_mean_diff_-3', 'O_rolling_mean_diff_-2', 'H_rolling_mean_diff_-2', 'L_rolling_mean_diff_-2', 'C_rolling_mean_diff_-2', 'O_rolling_mean_diff_-1', 'H_rolling_mean_diff_-1', 'L_rolling_mean_diff_-1', 'C_rolling_mean_diff_-1', 'O_rolling_mean_diff_0', 'H_rolling_mean_diff_0', 'L_rolling_mean_diff_0', 'C_rolling_mean_diff_0', 'O_rolling_mean_diff_1', 'H_rolling_mean_diff_1', 'L_rolling_mean_diff_1', 'C_rolling_mean_diff_1', 'O_rolling_mean_diff_2', 'H_rolling_mean_diff_2', 'L_rolling_mean_diff_2', 'C_rolling_mean_diff_2', 'PCA1', 'PCA2', 'PCA3', 'PCA4', 'PCA5', 'PCA6', 'PCA7', 'PCA8', 'PCA9', 'PCA10', 'PCA11', 'PCA12']\n",
      "Merging the scaled data and the unscalable data back together with pd.concat: EURJPY1440.csv (4950, 232)\n",
      "Finished: EURJPY1440.csv (4950, 232)\n",
      "--------------------------------\n",
      "Processing:  EURGBP1440.csv Number  2  of  11\n",
      "We now have: (4950, 232) rows of data!\n",
      "Reading in Date, OHLCV, Supply/Demand\n",
      "Renaming df_ohlc column headers for clarity\n",
      "Reading in Rectangle data\n",
      "Renaming df_rects column headers for clarity\n",
      "Identifying supply/demand with supply_or_demand func: EURGBP1440.csv (4951, 12)\n",
      "~~~\n",
      "Identifying zone ends with zone_ender func: EURGBP1440.csv (4951, 14)\n",
      "~~~\n",
      "Your df_norm columns: Index(['O', 'H', 'L', 'C', 'V'], dtype='object')\n",
      "Your df_non_norm columns: Index(['Epoch Date', 'Supply/Demand', 'Object Name', 'Epoch Date Start',\n",
      "       'Epoch Date End', 'Proximal', 'Distal', 'supply_demand',\n",
      "       'rectangle_here', 'Proximal_match_-3_O', 'Proximal_match_-2_O',\n",
      "       'Proximal_match_-1_O', 'Proximal_match_0_O', 'Proximal_match_1_O',\n",
      "       'Proximal_match_2_O', 'Proximal_match_3_O', 'Proximal_match_4_O',\n",
      "       'Proximal_match_5_O', 'Proximal_match_6_O', 'Distal_match_-3_O',\n",
      "       'Distal_match_-2_O', 'Distal_match_-1_O', 'Distal_match_0_O',\n",
      "       'Distal_match_1_O', 'Distal_match_2_O', 'Distal_match_3_O',\n",
      "       'Distal_match_4_O', 'Distal_match_5_O', 'Distal_match_6_O',\n",
      "       'Proximal_match_-3_H', 'Proximal_match_-2_H', 'Proximal_match_-1_H',\n",
      "       'Proximal_match_0_H', 'Proximal_match_1_H', 'Proximal_match_2_H',\n",
      "       'Proximal_match_3_H', 'Proximal_match_4_H', 'Proximal_match_5_H',\n",
      "       'Proximal_match_6_H', 'Distal_match_-3_H', 'Distal_match_-2_H',\n",
      "       'Distal_match_-1_H', 'Distal_match_0_H', 'Distal_match_1_H',\n",
      "       'Distal_match_2_H', 'Distal_match_3_H', 'Distal_match_4_H',\n",
      "       'Distal_match_5_H', 'Distal_match_6_H', 'Proximal_match_-3_L',\n",
      "       'Proximal_match_-2_L', 'Proximal_match_-1_L', 'Proximal_match_0_L',\n",
      "       'Proximal_match_1_L', 'Proximal_match_2_L', 'Proximal_match_3_L',\n",
      "       'Proximal_match_4_L', 'Proximal_match_5_L', 'Proximal_match_6_L',\n",
      "       'Distal_match_-3_L', 'Distal_match_-2_L', 'Distal_match_-1_L',\n",
      "       'Distal_match_0_L', 'Distal_match_1_L', 'Distal_match_2_L',\n",
      "       'Distal_match_3_L', 'Distal_match_4_L', 'Distal_match_5_L',\n",
      "       'Distal_match_6_L', 'Proximal_match_-3_C', 'Proximal_match_-2_C',\n",
      "       'Proximal_match_-1_C', 'Proximal_match_0_C', 'Proximal_match_1_C',\n",
      "       'Proximal_match_2_C', 'Proximal_match_3_C', 'Proximal_match_4_C',\n",
      "       'Proximal_match_5_C', 'Proximal_match_6_C', 'Distal_match_-3_C',\n",
      "       'Distal_match_-2_C', 'Distal_match_-1_C', 'Distal_match_0_C',\n",
      "       'Distal_match_1_C', 'Distal_match_2_C', 'Distal_match_3_C',\n",
      "       'Distal_match_4_C', 'Distal_match_5_C', 'Distal_match_6_C'],\n",
      "      dtype='object')\n",
      "Generating features:  Difference between open and close\n",
      "Shape is now: (4951, 6)\n",
      "~~~\n",
      "Generating features:  Range between high and low\n",
      "Shape is now: (4951, 7)\n",
      "~~~\n",
      "Generating features:  Generic lagged data\n",
      "Generating features:  Diffs over time for lookforward/lookback range\n",
      "Generating features:  Rolling mean for yesterday, today, tomorrow range\n",
      "Your df_scale_with_PCA: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 'PCA1', 'PCA2', 'PCA3', 'PCA4', 'PCA5', 'PCA6', 'PCA7', 'PCA8', 'PCA9', 'PCA10', 'PCA11', 'PCA12']\n",
      "Your df_scale_with_PCA columns are: ['O', 'H', 'L', 'C', 'V', 'change_open_close', 'range_high_low', 'O_std_dev', 'H_std_dev', 'L_std_dev', 'C_std_dev', 'O_rolling_mean', 'H_rolling_mean', 'L_rolling_mean', 'C_rolling_mean', 'change_open_close_rolling_mean', 'rolling_mean_range_HL', 'lag_-3_O', 'lag_-2_O', 'lag_-1_O', 'lag_0_O', 'lag_1_O', 'lag_2_O', 'lag_3_O', 'lag_4_O', 'lag_5_O', 'lag_6_O', 'lag_-3_H', 'lag_-2_H', 'lag_-1_H', 'lag_0_H', 'lag_1_H', 'lag_2_H', 'lag_3_H', 'lag_4_H', 'lag_5_H', 'lag_6_H', 'lag_-3_L', 'lag_-2_L', 'lag_-1_L', 'lag_0_L', 'lag_1_L', 'lag_2_L', 'lag_3_L', 'lag_4_L', 'lag_5_L', 'lag_6_L', 'lag_-3_C', 'lag_-2_C', 'lag_-1_C', 'lag_0_C', 'lag_1_C', 'lag_2_C', 'lag_3_C', 'lag_4_C', 'lag_5_C', 'lag_6_C', 'O_diff_-3', 'H_diff_-3', 'L_diff_-3', 'C_diff_-3', 'change_open_close_diff_-3', 'O_diff_-2', 'H_diff_-2', 'L_diff_-2', 'C_diff_-2', 'change_open_close_diff_-2', 'O_diff_-1', 'H_diff_-1', 'L_diff_-1', 'C_diff_-1', 'change_open_close_diff_-1', 'O_diff_0', 'H_diff_0', 'L_diff_0', 'C_diff_0', 'change_open_close_diff_0', 'O_diff_1', 'H_diff_1', 'L_diff_1', 'C_diff_1', 'change_open_close_diff_1', 'O_diff_2', 'H_diff_2', 'L_diff_2', 'C_diff_2', 'change_open_close_diff_2', 'O_diff_3', 'H_diff_3', 'L_diff_3', 'C_diff_3', 'change_open_close_diff_3', 'O_diff_4', 'H_diff_4', 'L_diff_4', 'C_diff_4', 'change_open_close_diff_4', 'O_diff_5', 'H_diff_5', 'L_diff_5', 'C_diff_5', 'change_open_close_diff_5', 'O_diff_6', 'H_diff_6', 'L_diff_6', 'C_diff_6', 'change_open_close_diff_6', 'O_rolling_mean_diff_-3', 'H_rolling_mean_diff_-3', 'L_rolling_mean_diff_-3', 'C_rolling_mean_diff_-3', 'O_rolling_mean_diff_-2', 'H_rolling_mean_diff_-2', 'L_rolling_mean_diff_-2', 'C_rolling_mean_diff_-2', 'O_rolling_mean_diff_-1', 'H_rolling_mean_diff_-1', 'L_rolling_mean_diff_-1', 'C_rolling_mean_diff_-1', 'O_rolling_mean_diff_0', 'H_rolling_mean_diff_0', 'L_rolling_mean_diff_0', 'C_rolling_mean_diff_0', 'O_rolling_mean_diff_1', 'H_rolling_mean_diff_1', 'L_rolling_mean_diff_1', 'C_rolling_mean_diff_1', 'O_rolling_mean_diff_2', 'H_rolling_mean_diff_2', 'L_rolling_mean_diff_2', 'C_rolling_mean_diff_2', 'PCA1', 'PCA2', 'PCA3', 'PCA4', 'PCA5', 'PCA6', 'PCA7', 'PCA8', 'PCA9', 'PCA10', 'PCA11', 'PCA12']\n",
      "Merging the scaled data and the unscalable data back together with pd.concat: EURGBP1440.csv (4951, 232)\n",
      "Finished: EURGBP1440.csv (4951, 232)\n",
      "--------------------------------\n",
      "Processing:  USDCAD1440.csv Number  3  of  11\n",
      "We now have: (9901, 232) rows of data!\n",
      "Reading in Date, OHLCV, Supply/Demand\n",
      "Renaming df_ohlc column headers for clarity\n",
      "Reading in Rectangle data\n",
      "Renaming df_rects column headers for clarity\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Identifying supply/demand with supply_or_demand func: USDCAD1440.csv (4943, 12)\n",
      "~~~\n",
      "Identifying zone ends with zone_ender func: USDCAD1440.csv (4943, 14)\n",
      "~~~\n",
      "Your df_norm columns: Index(['O', 'H', 'L', 'C', 'V'], dtype='object')\n",
      "Your df_non_norm columns: Index(['Epoch Date', 'Supply/Demand', 'Object Name', 'Epoch Date Start',\n",
      "       'Epoch Date End', 'Proximal', 'Distal', 'supply_demand',\n",
      "       'rectangle_here', 'Proximal_match_-3_O', 'Proximal_match_-2_O',\n",
      "       'Proximal_match_-1_O', 'Proximal_match_0_O', 'Proximal_match_1_O',\n",
      "       'Proximal_match_2_O', 'Proximal_match_3_O', 'Proximal_match_4_O',\n",
      "       'Proximal_match_5_O', 'Proximal_match_6_O', 'Distal_match_-3_O',\n",
      "       'Distal_match_-2_O', 'Distal_match_-1_O', 'Distal_match_0_O',\n",
      "       'Distal_match_1_O', 'Distal_match_2_O', 'Distal_match_3_O',\n",
      "       'Distal_match_4_O', 'Distal_match_5_O', 'Distal_match_6_O',\n",
      "       'Proximal_match_-3_H', 'Proximal_match_-2_H', 'Proximal_match_-1_H',\n",
      "       'Proximal_match_0_H', 'Proximal_match_1_H', 'Proximal_match_2_H',\n",
      "       'Proximal_match_3_H', 'Proximal_match_4_H', 'Proximal_match_5_H',\n",
      "       'Proximal_match_6_H', 'Distal_match_-3_H', 'Distal_match_-2_H',\n",
      "       'Distal_match_-1_H', 'Distal_match_0_H', 'Distal_match_1_H',\n",
      "       'Distal_match_2_H', 'Distal_match_3_H', 'Distal_match_4_H',\n",
      "       'Distal_match_5_H', 'Distal_match_6_H', 'Proximal_match_-3_L',\n",
      "       'Proximal_match_-2_L', 'Proximal_match_-1_L', 'Proximal_match_0_L',\n",
      "       'Proximal_match_1_L', 'Proximal_match_2_L', 'Proximal_match_3_L',\n",
      "       'Proximal_match_4_L', 'Proximal_match_5_L', 'Proximal_match_6_L',\n",
      "       'Distal_match_-3_L', 'Distal_match_-2_L', 'Distal_match_-1_L',\n",
      "       'Distal_match_0_L', 'Distal_match_1_L', 'Distal_match_2_L',\n",
      "       'Distal_match_3_L', 'Distal_match_4_L', 'Distal_match_5_L',\n",
      "       'Distal_match_6_L', 'Proximal_match_-3_C', 'Proximal_match_-2_C',\n",
      "       'Proximal_match_-1_C', 'Proximal_match_0_C', 'Proximal_match_1_C',\n",
      "       'Proximal_match_2_C', 'Proximal_match_3_C', 'Proximal_match_4_C',\n",
      "       'Proximal_match_5_C', 'Proximal_match_6_C', 'Distal_match_-3_C',\n",
      "       'Distal_match_-2_C', 'Distal_match_-1_C', 'Distal_match_0_C',\n",
      "       'Distal_match_1_C', 'Distal_match_2_C', 'Distal_match_3_C',\n",
      "       'Distal_match_4_C', 'Distal_match_5_C', 'Distal_match_6_C'],\n",
      "      dtype='object')\n",
      "Generating features:  Difference between open and close\n",
      "Shape is now: (4943, 6)\n",
      "~~~\n",
      "Generating features:  Range between high and low\n",
      "Shape is now: (4943, 7)\n",
      "~~~\n",
      "Generating features:  Generic lagged data\n",
      "Generating features:  Diffs over time for lookforward/lookback range\n",
      "Generating features:  Rolling mean for yesterday, today, tomorrow range\n",
      "Your df_scale_with_PCA: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 'PCA1', 'PCA2', 'PCA3', 'PCA4', 'PCA5', 'PCA6', 'PCA7', 'PCA8', 'PCA9', 'PCA10', 'PCA11', 'PCA12']\n",
      "Your df_scale_with_PCA columns are: ['O', 'H', 'L', 'C', 'V', 'change_open_close', 'range_high_low', 'O_std_dev', 'H_std_dev', 'L_std_dev', 'C_std_dev', 'O_rolling_mean', 'H_rolling_mean', 'L_rolling_mean', 'C_rolling_mean', 'change_open_close_rolling_mean', 'rolling_mean_range_HL', 'lag_-3_O', 'lag_-2_O', 'lag_-1_O', 'lag_0_O', 'lag_1_O', 'lag_2_O', 'lag_3_O', 'lag_4_O', 'lag_5_O', 'lag_6_O', 'lag_-3_H', 'lag_-2_H', 'lag_-1_H', 'lag_0_H', 'lag_1_H', 'lag_2_H', 'lag_3_H', 'lag_4_H', 'lag_5_H', 'lag_6_H', 'lag_-3_L', 'lag_-2_L', 'lag_-1_L', 'lag_0_L', 'lag_1_L', 'lag_2_L', 'lag_3_L', 'lag_4_L', 'lag_5_L', 'lag_6_L', 'lag_-3_C', 'lag_-2_C', 'lag_-1_C', 'lag_0_C', 'lag_1_C', 'lag_2_C', 'lag_3_C', 'lag_4_C', 'lag_5_C', 'lag_6_C', 'O_diff_-3', 'H_diff_-3', 'L_diff_-3', 'C_diff_-3', 'change_open_close_diff_-3', 'O_diff_-2', 'H_diff_-2', 'L_diff_-2', 'C_diff_-2', 'change_open_close_diff_-2', 'O_diff_-1', 'H_diff_-1', 'L_diff_-1', 'C_diff_-1', 'change_open_close_diff_-1', 'O_diff_0', 'H_diff_0', 'L_diff_0', 'C_diff_0', 'change_open_close_diff_0', 'O_diff_1', 'H_diff_1', 'L_diff_1', 'C_diff_1', 'change_open_close_diff_1', 'O_diff_2', 'H_diff_2', 'L_diff_2', 'C_diff_2', 'change_open_close_diff_2', 'O_diff_3', 'H_diff_3', 'L_diff_3', 'C_diff_3', 'change_open_close_diff_3', 'O_diff_4', 'H_diff_4', 'L_diff_4', 'C_diff_4', 'change_open_close_diff_4', 'O_diff_5', 'H_diff_5', 'L_diff_5', 'C_diff_5', 'change_open_close_diff_5', 'O_diff_6', 'H_diff_6', 'L_diff_6', 'C_diff_6', 'change_open_close_diff_6', 'O_rolling_mean_diff_-3', 'H_rolling_mean_diff_-3', 'L_rolling_mean_diff_-3', 'C_rolling_mean_diff_-3', 'O_rolling_mean_diff_-2', 'H_rolling_mean_diff_-2', 'L_rolling_mean_diff_-2', 'C_rolling_mean_diff_-2', 'O_rolling_mean_diff_-1', 'H_rolling_mean_diff_-1', 'L_rolling_mean_diff_-1', 'C_rolling_mean_diff_-1', 'O_rolling_mean_diff_0', 'H_rolling_mean_diff_0', 'L_rolling_mean_diff_0', 'C_rolling_mean_diff_0', 'O_rolling_mean_diff_1', 'H_rolling_mean_diff_1', 'L_rolling_mean_diff_1', 'C_rolling_mean_diff_1', 'O_rolling_mean_diff_2', 'H_rolling_mean_diff_2', 'L_rolling_mean_diff_2', 'C_rolling_mean_diff_2', 'PCA1', 'PCA2', 'PCA3', 'PCA4', 'PCA5', 'PCA6', 'PCA7', 'PCA8', 'PCA9', 'PCA10', 'PCA11', 'PCA12']\n",
      "Merging the scaled data and the unscalable data back together with pd.concat: USDCAD1440.csv (4943, 232)\n",
      "Finished: USDCAD1440.csv (4943, 232)\n",
      "--------------------------------\n",
      "Processing:  GBPUSD1440.csv Number  4  of  11\n",
      "We now have: (14844, 232) rows of data!\n",
      "Reading in Date, OHLCV, Supply/Demand\n",
      "Renaming df_ohlc column headers for clarity\n",
      "Reading in Rectangle data\n",
      "Renaming df_rects column headers for clarity\n",
      "Identifying supply/demand with supply_or_demand func: GBPUSD1440.csv (4516, 12)\n",
      "~~~\n",
      "Identifying zone ends with zone_ender func: GBPUSD1440.csv (4516, 14)\n",
      "~~~\n",
      "Your df_norm columns: Index(['O', 'H', 'L', 'C', 'V'], dtype='object')\n",
      "Your df_non_norm columns: Index(['Epoch Date', 'Supply/Demand', 'Object Name', 'Epoch Date Start',\n",
      "       'Epoch Date End', 'Proximal', 'Distal', 'supply_demand',\n",
      "       'rectangle_here', 'Proximal_match_-3_O', 'Proximal_match_-2_O',\n",
      "       'Proximal_match_-1_O', 'Proximal_match_0_O', 'Proximal_match_1_O',\n",
      "       'Proximal_match_2_O', 'Proximal_match_3_O', 'Proximal_match_4_O',\n",
      "       'Proximal_match_5_O', 'Proximal_match_6_O', 'Distal_match_-3_O',\n",
      "       'Distal_match_-2_O', 'Distal_match_-1_O', 'Distal_match_0_O',\n",
      "       'Distal_match_1_O', 'Distal_match_2_O', 'Distal_match_3_O',\n",
      "       'Distal_match_4_O', 'Distal_match_5_O', 'Distal_match_6_O',\n",
      "       'Proximal_match_-3_H', 'Proximal_match_-2_H', 'Proximal_match_-1_H',\n",
      "       'Proximal_match_0_H', 'Proximal_match_1_H', 'Proximal_match_2_H',\n",
      "       'Proximal_match_3_H', 'Proximal_match_4_H', 'Proximal_match_5_H',\n",
      "       'Proximal_match_6_H', 'Distal_match_-3_H', 'Distal_match_-2_H',\n",
      "       'Distal_match_-1_H', 'Distal_match_0_H', 'Distal_match_1_H',\n",
      "       'Distal_match_2_H', 'Distal_match_3_H', 'Distal_match_4_H',\n",
      "       'Distal_match_5_H', 'Distal_match_6_H', 'Proximal_match_-3_L',\n",
      "       'Proximal_match_-2_L', 'Proximal_match_-1_L', 'Proximal_match_0_L',\n",
      "       'Proximal_match_1_L', 'Proximal_match_2_L', 'Proximal_match_3_L',\n",
      "       'Proximal_match_4_L', 'Proximal_match_5_L', 'Proximal_match_6_L',\n",
      "       'Distal_match_-3_L', 'Distal_match_-2_L', 'Distal_match_-1_L',\n",
      "       'Distal_match_0_L', 'Distal_match_1_L', 'Distal_match_2_L',\n",
      "       'Distal_match_3_L', 'Distal_match_4_L', 'Distal_match_5_L',\n",
      "       'Distal_match_6_L', 'Proximal_match_-3_C', 'Proximal_match_-2_C',\n",
      "       'Proximal_match_-1_C', 'Proximal_match_0_C', 'Proximal_match_1_C',\n",
      "       'Proximal_match_2_C', 'Proximal_match_3_C', 'Proximal_match_4_C',\n",
      "       'Proximal_match_5_C', 'Proximal_match_6_C', 'Distal_match_-3_C',\n",
      "       'Distal_match_-2_C', 'Distal_match_-1_C', 'Distal_match_0_C',\n",
      "       'Distal_match_1_C', 'Distal_match_2_C', 'Distal_match_3_C',\n",
      "       'Distal_match_4_C', 'Distal_match_5_C', 'Distal_match_6_C'],\n",
      "      dtype='object')\n",
      "Generating features:  Difference between open and close\n",
      "Shape is now: (4516, 6)\n",
      "~~~\n",
      "Generating features:  Range between high and low\n",
      "Shape is now: (4516, 7)\n",
      "~~~\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating features:  Generic lagged data\n",
      "Generating features:  Diffs over time for lookforward/lookback range\n",
      "Generating features:  Rolling mean for yesterday, today, tomorrow range\n",
      "Your df_scale_with_PCA: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 'PCA1', 'PCA2', 'PCA3', 'PCA4', 'PCA5', 'PCA6', 'PCA7', 'PCA8', 'PCA9', 'PCA10', 'PCA11', 'PCA12']\n",
      "Your df_scale_with_PCA columns are: ['O', 'H', 'L', 'C', 'V', 'change_open_close', 'range_high_low', 'O_std_dev', 'H_std_dev', 'L_std_dev', 'C_std_dev', 'O_rolling_mean', 'H_rolling_mean', 'L_rolling_mean', 'C_rolling_mean', 'change_open_close_rolling_mean', 'rolling_mean_range_HL', 'lag_-3_O', 'lag_-2_O', 'lag_-1_O', 'lag_0_O', 'lag_1_O', 'lag_2_O', 'lag_3_O', 'lag_4_O', 'lag_5_O', 'lag_6_O', 'lag_-3_H', 'lag_-2_H', 'lag_-1_H', 'lag_0_H', 'lag_1_H', 'lag_2_H', 'lag_3_H', 'lag_4_H', 'lag_5_H', 'lag_6_H', 'lag_-3_L', 'lag_-2_L', 'lag_-1_L', 'lag_0_L', 'lag_1_L', 'lag_2_L', 'lag_3_L', 'lag_4_L', 'lag_5_L', 'lag_6_L', 'lag_-3_C', 'lag_-2_C', 'lag_-1_C', 'lag_0_C', 'lag_1_C', 'lag_2_C', 'lag_3_C', 'lag_4_C', 'lag_5_C', 'lag_6_C', 'O_diff_-3', 'H_diff_-3', 'L_diff_-3', 'C_diff_-3', 'change_open_close_diff_-3', 'O_diff_-2', 'H_diff_-2', 'L_diff_-2', 'C_diff_-2', 'change_open_close_diff_-2', 'O_diff_-1', 'H_diff_-1', 'L_diff_-1', 'C_diff_-1', 'change_open_close_diff_-1', 'O_diff_0', 'H_diff_0', 'L_diff_0', 'C_diff_0', 'change_open_close_diff_0', 'O_diff_1', 'H_diff_1', 'L_diff_1', 'C_diff_1', 'change_open_close_diff_1', 'O_diff_2', 'H_diff_2', 'L_diff_2', 'C_diff_2', 'change_open_close_diff_2', 'O_diff_3', 'H_diff_3', 'L_diff_3', 'C_diff_3', 'change_open_close_diff_3', 'O_diff_4', 'H_diff_4', 'L_diff_4', 'C_diff_4', 'change_open_close_diff_4', 'O_diff_5', 'H_diff_5', 'L_diff_5', 'C_diff_5', 'change_open_close_diff_5', 'O_diff_6', 'H_diff_6', 'L_diff_6', 'C_diff_6', 'change_open_close_diff_6', 'O_rolling_mean_diff_-3', 'H_rolling_mean_diff_-3', 'L_rolling_mean_diff_-3', 'C_rolling_mean_diff_-3', 'O_rolling_mean_diff_-2', 'H_rolling_mean_diff_-2', 'L_rolling_mean_diff_-2', 'C_rolling_mean_diff_-2', 'O_rolling_mean_diff_-1', 'H_rolling_mean_diff_-1', 'L_rolling_mean_diff_-1', 'C_rolling_mean_diff_-1', 'O_rolling_mean_diff_0', 'H_rolling_mean_diff_0', 'L_rolling_mean_diff_0', 'C_rolling_mean_diff_0', 'O_rolling_mean_diff_1', 'H_rolling_mean_diff_1', 'L_rolling_mean_diff_1', 'C_rolling_mean_diff_1', 'O_rolling_mean_diff_2', 'H_rolling_mean_diff_2', 'L_rolling_mean_diff_2', 'C_rolling_mean_diff_2', 'PCA1', 'PCA2', 'PCA3', 'PCA4', 'PCA5', 'PCA6', 'PCA7', 'PCA8', 'PCA9', 'PCA10', 'PCA11', 'PCA12']\n",
      "Merging the scaled data and the unscalable data back together with pd.concat: GBPUSD1440.csv (4516, 232)\n",
      "Finished: GBPUSD1440.csv (4516, 232)\n",
      "--------------------------------\n",
      "Processing:  EURUSD14402.csv Number  5  of  11\n",
      "We now have: (19360, 232) rows of data!\n",
      "Reading in Date, OHLCV, Supply/Demand\n",
      "Renaming df_ohlc column headers for clarity\n",
      "Reading in Rectangle data\n",
      "Renaming df_rects column headers for clarity\n",
      "Identifying supply/demand with supply_or_demand func: EURUSD14402.csv (4949, 12)\n",
      "~~~\n",
      "Identifying zone ends with zone_ender func: EURUSD14402.csv (4949, 14)\n",
      "~~~\n",
      "Your df_norm columns: Index(['O', 'H', 'L', 'C', 'V'], dtype='object')\n",
      "Your df_non_norm columns: Index(['Epoch Date', 'Supply/Demand', 'Object Name', 'Epoch Date Start',\n",
      "       'Epoch Date End', 'Proximal', 'Distal', 'supply_demand',\n",
      "       'rectangle_here', 'Proximal_match_-3_O', 'Proximal_match_-2_O',\n",
      "       'Proximal_match_-1_O', 'Proximal_match_0_O', 'Proximal_match_1_O',\n",
      "       'Proximal_match_2_O', 'Proximal_match_3_O', 'Proximal_match_4_O',\n",
      "       'Proximal_match_5_O', 'Proximal_match_6_O', 'Distal_match_-3_O',\n",
      "       'Distal_match_-2_O', 'Distal_match_-1_O', 'Distal_match_0_O',\n",
      "       'Distal_match_1_O', 'Distal_match_2_O', 'Distal_match_3_O',\n",
      "       'Distal_match_4_O', 'Distal_match_5_O', 'Distal_match_6_O',\n",
      "       'Proximal_match_-3_H', 'Proximal_match_-2_H', 'Proximal_match_-1_H',\n",
      "       'Proximal_match_0_H', 'Proximal_match_1_H', 'Proximal_match_2_H',\n",
      "       'Proximal_match_3_H', 'Proximal_match_4_H', 'Proximal_match_5_H',\n",
      "       'Proximal_match_6_H', 'Distal_match_-3_H', 'Distal_match_-2_H',\n",
      "       'Distal_match_-1_H', 'Distal_match_0_H', 'Distal_match_1_H',\n",
      "       'Distal_match_2_H', 'Distal_match_3_H', 'Distal_match_4_H',\n",
      "       'Distal_match_5_H', 'Distal_match_6_H', 'Proximal_match_-3_L',\n",
      "       'Proximal_match_-2_L', 'Proximal_match_-1_L', 'Proximal_match_0_L',\n",
      "       'Proximal_match_1_L', 'Proximal_match_2_L', 'Proximal_match_3_L',\n",
      "       'Proximal_match_4_L', 'Proximal_match_5_L', 'Proximal_match_6_L',\n",
      "       'Distal_match_-3_L', 'Distal_match_-2_L', 'Distal_match_-1_L',\n",
      "       'Distal_match_0_L', 'Distal_match_1_L', 'Distal_match_2_L',\n",
      "       'Distal_match_3_L', 'Distal_match_4_L', 'Distal_match_5_L',\n",
      "       'Distal_match_6_L', 'Proximal_match_-3_C', 'Proximal_match_-2_C',\n",
      "       'Proximal_match_-1_C', 'Proximal_match_0_C', 'Proximal_match_1_C',\n",
      "       'Proximal_match_2_C', 'Proximal_match_3_C', 'Proximal_match_4_C',\n",
      "       'Proximal_match_5_C', 'Proximal_match_6_C', 'Distal_match_-3_C',\n",
      "       'Distal_match_-2_C', 'Distal_match_-1_C', 'Distal_match_0_C',\n",
      "       'Distal_match_1_C', 'Distal_match_2_C', 'Distal_match_3_C',\n",
      "       'Distal_match_4_C', 'Distal_match_5_C', 'Distal_match_6_C'],\n",
      "      dtype='object')\n",
      "Generating features:  Difference between open and close\n",
      "Shape is now: (4949, 6)\n",
      "~~~\n",
      "Generating features:  Range between high and low\n",
      "Shape is now: (4949, 7)\n",
      "~~~\n",
      "Generating features:  Generic lagged data\n",
      "Generating features:  Diffs over time for lookforward/lookback range\n",
      "Generating features:  Rolling mean for yesterday, today, tomorrow range\n",
      "Your df_scale_with_PCA: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 'PCA1', 'PCA2', 'PCA3', 'PCA4', 'PCA5', 'PCA6', 'PCA7', 'PCA8', 'PCA9', 'PCA10', 'PCA11', 'PCA12']\n",
      "Your df_scale_with_PCA columns are: ['O', 'H', 'L', 'C', 'V', 'change_open_close', 'range_high_low', 'O_std_dev', 'H_std_dev', 'L_std_dev', 'C_std_dev', 'O_rolling_mean', 'H_rolling_mean', 'L_rolling_mean', 'C_rolling_mean', 'change_open_close_rolling_mean', 'rolling_mean_range_HL', 'lag_-3_O', 'lag_-2_O', 'lag_-1_O', 'lag_0_O', 'lag_1_O', 'lag_2_O', 'lag_3_O', 'lag_4_O', 'lag_5_O', 'lag_6_O', 'lag_-3_H', 'lag_-2_H', 'lag_-1_H', 'lag_0_H', 'lag_1_H', 'lag_2_H', 'lag_3_H', 'lag_4_H', 'lag_5_H', 'lag_6_H', 'lag_-3_L', 'lag_-2_L', 'lag_-1_L', 'lag_0_L', 'lag_1_L', 'lag_2_L', 'lag_3_L', 'lag_4_L', 'lag_5_L', 'lag_6_L', 'lag_-3_C', 'lag_-2_C', 'lag_-1_C', 'lag_0_C', 'lag_1_C', 'lag_2_C', 'lag_3_C', 'lag_4_C', 'lag_5_C', 'lag_6_C', 'O_diff_-3', 'H_diff_-3', 'L_diff_-3', 'C_diff_-3', 'change_open_close_diff_-3', 'O_diff_-2', 'H_diff_-2', 'L_diff_-2', 'C_diff_-2', 'change_open_close_diff_-2', 'O_diff_-1', 'H_diff_-1', 'L_diff_-1', 'C_diff_-1', 'change_open_close_diff_-1', 'O_diff_0', 'H_diff_0', 'L_diff_0', 'C_diff_0', 'change_open_close_diff_0', 'O_diff_1', 'H_diff_1', 'L_diff_1', 'C_diff_1', 'change_open_close_diff_1', 'O_diff_2', 'H_diff_2', 'L_diff_2', 'C_diff_2', 'change_open_close_diff_2', 'O_diff_3', 'H_diff_3', 'L_diff_3', 'C_diff_3', 'change_open_close_diff_3', 'O_diff_4', 'H_diff_4', 'L_diff_4', 'C_diff_4', 'change_open_close_diff_4', 'O_diff_5', 'H_diff_5', 'L_diff_5', 'C_diff_5', 'change_open_close_diff_5', 'O_diff_6', 'H_diff_6', 'L_diff_6', 'C_diff_6', 'change_open_close_diff_6', 'O_rolling_mean_diff_-3', 'H_rolling_mean_diff_-3', 'L_rolling_mean_diff_-3', 'C_rolling_mean_diff_-3', 'O_rolling_mean_diff_-2', 'H_rolling_mean_diff_-2', 'L_rolling_mean_diff_-2', 'C_rolling_mean_diff_-2', 'O_rolling_mean_diff_-1', 'H_rolling_mean_diff_-1', 'L_rolling_mean_diff_-1', 'C_rolling_mean_diff_-1', 'O_rolling_mean_diff_0', 'H_rolling_mean_diff_0', 'L_rolling_mean_diff_0', 'C_rolling_mean_diff_0', 'O_rolling_mean_diff_1', 'H_rolling_mean_diff_1', 'L_rolling_mean_diff_1', 'C_rolling_mean_diff_1', 'O_rolling_mean_diff_2', 'H_rolling_mean_diff_2', 'L_rolling_mean_diff_2', 'C_rolling_mean_diff_2', 'PCA1', 'PCA2', 'PCA3', 'PCA4', 'PCA5', 'PCA6', 'PCA7', 'PCA8', 'PCA9', 'PCA10', 'PCA11', 'PCA12']\n",
      "Merging the scaled data and the unscalable data back together with pd.concat: EURUSD14402.csv (4949, 232)\n",
      "Finished: EURUSD14402.csv (4949, 232)\n",
      "--------------------------------\n",
      "Processing:  USDCHF1440.csv Number  6  of  11\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We now have: (24309, 232) rows of data!\n",
      "Reading in Date, OHLCV, Supply/Demand\n",
      "Renaming df_ohlc column headers for clarity\n",
      "Reading in Rectangle data\n",
      "Renaming df_rects column headers for clarity\n",
      "Identifying supply/demand with supply_or_demand func: USDCHF1440.csv (4887, 12)\n",
      "~~~\n",
      "Identifying zone ends with zone_ender func: USDCHF1440.csv (4887, 14)\n",
      "~~~\n",
      "Your df_norm columns: Index(['O', 'H', 'L', 'C', 'V'], dtype='object')\n",
      "Your df_non_norm columns: Index(['Epoch Date', 'Supply/Demand', 'Object Name', 'Epoch Date Start',\n",
      "       'Epoch Date End', 'Proximal', 'Distal', 'supply_demand',\n",
      "       'rectangle_here', 'Proximal_match_-3_O', 'Proximal_match_-2_O',\n",
      "       'Proximal_match_-1_O', 'Proximal_match_0_O', 'Proximal_match_1_O',\n",
      "       'Proximal_match_2_O', 'Proximal_match_3_O', 'Proximal_match_4_O',\n",
      "       'Proximal_match_5_O', 'Proximal_match_6_O', 'Distal_match_-3_O',\n",
      "       'Distal_match_-2_O', 'Distal_match_-1_O', 'Distal_match_0_O',\n",
      "       'Distal_match_1_O', 'Distal_match_2_O', 'Distal_match_3_O',\n",
      "       'Distal_match_4_O', 'Distal_match_5_O', 'Distal_match_6_O',\n",
      "       'Proximal_match_-3_H', 'Proximal_match_-2_H', 'Proximal_match_-1_H',\n",
      "       'Proximal_match_0_H', 'Proximal_match_1_H', 'Proximal_match_2_H',\n",
      "       'Proximal_match_3_H', 'Proximal_match_4_H', 'Proximal_match_5_H',\n",
      "       'Proximal_match_6_H', 'Distal_match_-3_H', 'Distal_match_-2_H',\n",
      "       'Distal_match_-1_H', 'Distal_match_0_H', 'Distal_match_1_H',\n",
      "       'Distal_match_2_H', 'Distal_match_3_H', 'Distal_match_4_H',\n",
      "       'Distal_match_5_H', 'Distal_match_6_H', 'Proximal_match_-3_L',\n",
      "       'Proximal_match_-2_L', 'Proximal_match_-1_L', 'Proximal_match_0_L',\n",
      "       'Proximal_match_1_L', 'Proximal_match_2_L', 'Proximal_match_3_L',\n",
      "       'Proximal_match_4_L', 'Proximal_match_5_L', 'Proximal_match_6_L',\n",
      "       'Distal_match_-3_L', 'Distal_match_-2_L', 'Distal_match_-1_L',\n",
      "       'Distal_match_0_L', 'Distal_match_1_L', 'Distal_match_2_L',\n",
      "       'Distal_match_3_L', 'Distal_match_4_L', 'Distal_match_5_L',\n",
      "       'Distal_match_6_L', 'Proximal_match_-3_C', 'Proximal_match_-2_C',\n",
      "       'Proximal_match_-1_C', 'Proximal_match_0_C', 'Proximal_match_1_C',\n",
      "       'Proximal_match_2_C', 'Proximal_match_3_C', 'Proximal_match_4_C',\n",
      "       'Proximal_match_5_C', 'Proximal_match_6_C', 'Distal_match_-3_C',\n",
      "       'Distal_match_-2_C', 'Distal_match_-1_C', 'Distal_match_0_C',\n",
      "       'Distal_match_1_C', 'Distal_match_2_C', 'Distal_match_3_C',\n",
      "       'Distal_match_4_C', 'Distal_match_5_C', 'Distal_match_6_C'],\n",
      "      dtype='object')\n",
      "Generating features:  Difference between open and close\n",
      "Shape is now: (4887, 6)\n",
      "~~~\n",
      "Generating features:  Range between high and low\n",
      "Shape is now: (4887, 7)\n",
      "~~~\n",
      "Generating features:  Generic lagged data\n",
      "Generating features:  Diffs over time for lookforward/lookback range\n",
      "Generating features:  Rolling mean for yesterday, today, tomorrow range\n",
      "Your df_scale_with_PCA: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 'PCA1', 'PCA2', 'PCA3', 'PCA4', 'PCA5', 'PCA6', 'PCA7', 'PCA8', 'PCA9', 'PCA10', 'PCA11', 'PCA12']\n",
      "Your df_scale_with_PCA columns are: ['O', 'H', 'L', 'C', 'V', 'change_open_close', 'range_high_low', 'O_std_dev', 'H_std_dev', 'L_std_dev', 'C_std_dev', 'O_rolling_mean', 'H_rolling_mean', 'L_rolling_mean', 'C_rolling_mean', 'change_open_close_rolling_mean', 'rolling_mean_range_HL', 'lag_-3_O', 'lag_-2_O', 'lag_-1_O', 'lag_0_O', 'lag_1_O', 'lag_2_O', 'lag_3_O', 'lag_4_O', 'lag_5_O', 'lag_6_O', 'lag_-3_H', 'lag_-2_H', 'lag_-1_H', 'lag_0_H', 'lag_1_H', 'lag_2_H', 'lag_3_H', 'lag_4_H', 'lag_5_H', 'lag_6_H', 'lag_-3_L', 'lag_-2_L', 'lag_-1_L', 'lag_0_L', 'lag_1_L', 'lag_2_L', 'lag_3_L', 'lag_4_L', 'lag_5_L', 'lag_6_L', 'lag_-3_C', 'lag_-2_C', 'lag_-1_C', 'lag_0_C', 'lag_1_C', 'lag_2_C', 'lag_3_C', 'lag_4_C', 'lag_5_C', 'lag_6_C', 'O_diff_-3', 'H_diff_-3', 'L_diff_-3', 'C_diff_-3', 'change_open_close_diff_-3', 'O_diff_-2', 'H_diff_-2', 'L_diff_-2', 'C_diff_-2', 'change_open_close_diff_-2', 'O_diff_-1', 'H_diff_-1', 'L_diff_-1', 'C_diff_-1', 'change_open_close_diff_-1', 'O_diff_0', 'H_diff_0', 'L_diff_0', 'C_diff_0', 'change_open_close_diff_0', 'O_diff_1', 'H_diff_1', 'L_diff_1', 'C_diff_1', 'change_open_close_diff_1', 'O_diff_2', 'H_diff_2', 'L_diff_2', 'C_diff_2', 'change_open_close_diff_2', 'O_diff_3', 'H_diff_3', 'L_diff_3', 'C_diff_3', 'change_open_close_diff_3', 'O_diff_4', 'H_diff_4', 'L_diff_4', 'C_diff_4', 'change_open_close_diff_4', 'O_diff_5', 'H_diff_5', 'L_diff_5', 'C_diff_5', 'change_open_close_diff_5', 'O_diff_6', 'H_diff_6', 'L_diff_6', 'C_diff_6', 'change_open_close_diff_6', 'O_rolling_mean_diff_-3', 'H_rolling_mean_diff_-3', 'L_rolling_mean_diff_-3', 'C_rolling_mean_diff_-3', 'O_rolling_mean_diff_-2', 'H_rolling_mean_diff_-2', 'L_rolling_mean_diff_-2', 'C_rolling_mean_diff_-2', 'O_rolling_mean_diff_-1', 'H_rolling_mean_diff_-1', 'L_rolling_mean_diff_-1', 'C_rolling_mean_diff_-1', 'O_rolling_mean_diff_0', 'H_rolling_mean_diff_0', 'L_rolling_mean_diff_0', 'C_rolling_mean_diff_0', 'O_rolling_mean_diff_1', 'H_rolling_mean_diff_1', 'L_rolling_mean_diff_1', 'C_rolling_mean_diff_1', 'O_rolling_mean_diff_2', 'H_rolling_mean_diff_2', 'L_rolling_mean_diff_2', 'C_rolling_mean_diff_2', 'PCA1', 'PCA2', 'PCA3', 'PCA4', 'PCA5', 'PCA6', 'PCA7', 'PCA8', 'PCA9', 'PCA10', 'PCA11', 'PCA12']\n",
      "Merging the scaled data and the unscalable data back together with pd.concat: USDCHF1440.csv (4887, 232)\n",
      "Finished: USDCHF1440.csv (4887, 232)\n",
      "--------------------------------\n",
      "Processing:  EURAUD14402.csv Number  7  of  11\n",
      "We now have: (29196, 232) rows of data!\n",
      "Reading in Date, OHLCV, Supply/Demand\n",
      "Renaming df_ohlc column headers for clarity\n",
      "Reading in Rectangle data\n",
      "Renaming df_rects column headers for clarity\n",
      "Identifying supply/demand with supply_or_demand func: EURAUD14402.csv (4624, 12)\n",
      "~~~\n",
      "Identifying zone ends with zone_ender func: EURAUD14402.csv (4624, 14)\n",
      "~~~\n",
      "Your df_norm columns: Index(['O', 'H', 'L', 'C', 'V'], dtype='object')\n",
      "Your df_non_norm columns: Index(['Epoch Date', 'Supply/Demand', 'Object Name', 'Epoch Date Start',\n",
      "       'Epoch Date End', 'Proximal', 'Distal', 'supply_demand',\n",
      "       'rectangle_here', 'Proximal_match_-3_O', 'Proximal_match_-2_O',\n",
      "       'Proximal_match_-1_O', 'Proximal_match_0_O', 'Proximal_match_1_O',\n",
      "       'Proximal_match_2_O', 'Proximal_match_3_O', 'Proximal_match_4_O',\n",
      "       'Proximal_match_5_O', 'Proximal_match_6_O', 'Distal_match_-3_O',\n",
      "       'Distal_match_-2_O', 'Distal_match_-1_O', 'Distal_match_0_O',\n",
      "       'Distal_match_1_O', 'Distal_match_2_O', 'Distal_match_3_O',\n",
      "       'Distal_match_4_O', 'Distal_match_5_O', 'Distal_match_6_O',\n",
      "       'Proximal_match_-3_H', 'Proximal_match_-2_H', 'Proximal_match_-1_H',\n",
      "       'Proximal_match_0_H', 'Proximal_match_1_H', 'Proximal_match_2_H',\n",
      "       'Proximal_match_3_H', 'Proximal_match_4_H', 'Proximal_match_5_H',\n",
      "       'Proximal_match_6_H', 'Distal_match_-3_H', 'Distal_match_-2_H',\n",
      "       'Distal_match_-1_H', 'Distal_match_0_H', 'Distal_match_1_H',\n",
      "       'Distal_match_2_H', 'Distal_match_3_H', 'Distal_match_4_H',\n",
      "       'Distal_match_5_H', 'Distal_match_6_H', 'Proximal_match_-3_L',\n",
      "       'Proximal_match_-2_L', 'Proximal_match_-1_L', 'Proximal_match_0_L',\n",
      "       'Proximal_match_1_L', 'Proximal_match_2_L', 'Proximal_match_3_L',\n",
      "       'Proximal_match_4_L', 'Proximal_match_5_L', 'Proximal_match_6_L',\n",
      "       'Distal_match_-3_L', 'Distal_match_-2_L', 'Distal_match_-1_L',\n",
      "       'Distal_match_0_L', 'Distal_match_1_L', 'Distal_match_2_L',\n",
      "       'Distal_match_3_L', 'Distal_match_4_L', 'Distal_match_5_L',\n",
      "       'Distal_match_6_L', 'Proximal_match_-3_C', 'Proximal_match_-2_C',\n",
      "       'Proximal_match_-1_C', 'Proximal_match_0_C', 'Proximal_match_1_C',\n",
      "       'Proximal_match_2_C', 'Proximal_match_3_C', 'Proximal_match_4_C',\n",
      "       'Proximal_match_5_C', 'Proximal_match_6_C', 'Distal_match_-3_C',\n",
      "       'Distal_match_-2_C', 'Distal_match_-1_C', 'Distal_match_0_C',\n",
      "       'Distal_match_1_C', 'Distal_match_2_C', 'Distal_match_3_C',\n",
      "       'Distal_match_4_C', 'Distal_match_5_C', 'Distal_match_6_C'],\n",
      "      dtype='object')\n",
      "Generating features:  Difference between open and close\n",
      "Shape is now: (4624, 6)\n",
      "~~~\n",
      "Generating features:  Range between high and low\n",
      "Shape is now: (4624, 7)\n",
      "~~~\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating features:  Generic lagged data\n",
      "Generating features:  Diffs over time for lookforward/lookback range\n",
      "Generating features:  Rolling mean for yesterday, today, tomorrow range\n",
      "Your df_scale_with_PCA: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 'PCA1', 'PCA2', 'PCA3', 'PCA4', 'PCA5', 'PCA6', 'PCA7', 'PCA8', 'PCA9', 'PCA10', 'PCA11', 'PCA12']\n",
      "Your df_scale_with_PCA columns are: ['O', 'H', 'L', 'C', 'V', 'change_open_close', 'range_high_low', 'O_std_dev', 'H_std_dev', 'L_std_dev', 'C_std_dev', 'O_rolling_mean', 'H_rolling_mean', 'L_rolling_mean', 'C_rolling_mean', 'change_open_close_rolling_mean', 'rolling_mean_range_HL', 'lag_-3_O', 'lag_-2_O', 'lag_-1_O', 'lag_0_O', 'lag_1_O', 'lag_2_O', 'lag_3_O', 'lag_4_O', 'lag_5_O', 'lag_6_O', 'lag_-3_H', 'lag_-2_H', 'lag_-1_H', 'lag_0_H', 'lag_1_H', 'lag_2_H', 'lag_3_H', 'lag_4_H', 'lag_5_H', 'lag_6_H', 'lag_-3_L', 'lag_-2_L', 'lag_-1_L', 'lag_0_L', 'lag_1_L', 'lag_2_L', 'lag_3_L', 'lag_4_L', 'lag_5_L', 'lag_6_L', 'lag_-3_C', 'lag_-2_C', 'lag_-1_C', 'lag_0_C', 'lag_1_C', 'lag_2_C', 'lag_3_C', 'lag_4_C', 'lag_5_C', 'lag_6_C', 'O_diff_-3', 'H_diff_-3', 'L_diff_-3', 'C_diff_-3', 'change_open_close_diff_-3', 'O_diff_-2', 'H_diff_-2', 'L_diff_-2', 'C_diff_-2', 'change_open_close_diff_-2', 'O_diff_-1', 'H_diff_-1', 'L_diff_-1', 'C_diff_-1', 'change_open_close_diff_-1', 'O_diff_0', 'H_diff_0', 'L_diff_0', 'C_diff_0', 'change_open_close_diff_0', 'O_diff_1', 'H_diff_1', 'L_diff_1', 'C_diff_1', 'change_open_close_diff_1', 'O_diff_2', 'H_diff_2', 'L_diff_2', 'C_diff_2', 'change_open_close_diff_2', 'O_diff_3', 'H_diff_3', 'L_diff_3', 'C_diff_3', 'change_open_close_diff_3', 'O_diff_4', 'H_diff_4', 'L_diff_4', 'C_diff_4', 'change_open_close_diff_4', 'O_diff_5', 'H_diff_5', 'L_diff_5', 'C_diff_5', 'change_open_close_diff_5', 'O_diff_6', 'H_diff_6', 'L_diff_6', 'C_diff_6', 'change_open_close_diff_6', 'O_rolling_mean_diff_-3', 'H_rolling_mean_diff_-3', 'L_rolling_mean_diff_-3', 'C_rolling_mean_diff_-3', 'O_rolling_mean_diff_-2', 'H_rolling_mean_diff_-2', 'L_rolling_mean_diff_-2', 'C_rolling_mean_diff_-2', 'O_rolling_mean_diff_-1', 'H_rolling_mean_diff_-1', 'L_rolling_mean_diff_-1', 'C_rolling_mean_diff_-1', 'O_rolling_mean_diff_0', 'H_rolling_mean_diff_0', 'L_rolling_mean_diff_0', 'C_rolling_mean_diff_0', 'O_rolling_mean_diff_1', 'H_rolling_mean_diff_1', 'L_rolling_mean_diff_1', 'C_rolling_mean_diff_1', 'O_rolling_mean_diff_2', 'H_rolling_mean_diff_2', 'L_rolling_mean_diff_2', 'C_rolling_mean_diff_2', 'PCA1', 'PCA2', 'PCA3', 'PCA4', 'PCA5', 'PCA6', 'PCA7', 'PCA8', 'PCA9', 'PCA10', 'PCA11', 'PCA12']\n",
      "Merging the scaled data and the unscalable data back together with pd.concat: EURAUD14402.csv (4624, 232)\n",
      "Finished: EURAUD14402.csv (4624, 232)\n",
      "--------------------------------\n",
      "Processing:  AUDUSD1440.csv Number  8  of  11\n",
      "We now have: (33820, 232) rows of data!\n",
      "Reading in Date, OHLCV, Supply/Demand\n",
      "Renaming df_ohlc column headers for clarity\n",
      "Reading in Rectangle data\n",
      "Renaming df_rects column headers for clarity\n",
      "Identifying supply/demand with supply_or_demand func: AUDUSD1440.csv (4951, 12)\n",
      "~~~\n",
      "Identifying zone ends with zone_ender func: AUDUSD1440.csv (4951, 14)\n",
      "~~~\n",
      "Your df_norm columns: Index(['O', 'H', 'L', 'C', 'V'], dtype='object')\n",
      "Your df_non_norm columns: Index(['Epoch Date', 'Supply/Demand', 'Object Name', 'Epoch Date Start',\n",
      "       'Epoch Date End', 'Proximal', 'Distal', 'supply_demand',\n",
      "       'rectangle_here', 'Proximal_match_-3_O', 'Proximal_match_-2_O',\n",
      "       'Proximal_match_-1_O', 'Proximal_match_0_O', 'Proximal_match_1_O',\n",
      "       'Proximal_match_2_O', 'Proximal_match_3_O', 'Proximal_match_4_O',\n",
      "       'Proximal_match_5_O', 'Proximal_match_6_O', 'Distal_match_-3_O',\n",
      "       'Distal_match_-2_O', 'Distal_match_-1_O', 'Distal_match_0_O',\n",
      "       'Distal_match_1_O', 'Distal_match_2_O', 'Distal_match_3_O',\n",
      "       'Distal_match_4_O', 'Distal_match_5_O', 'Distal_match_6_O',\n",
      "       'Proximal_match_-3_H', 'Proximal_match_-2_H', 'Proximal_match_-1_H',\n",
      "       'Proximal_match_0_H', 'Proximal_match_1_H', 'Proximal_match_2_H',\n",
      "       'Proximal_match_3_H', 'Proximal_match_4_H', 'Proximal_match_5_H',\n",
      "       'Proximal_match_6_H', 'Distal_match_-3_H', 'Distal_match_-2_H',\n",
      "       'Distal_match_-1_H', 'Distal_match_0_H', 'Distal_match_1_H',\n",
      "       'Distal_match_2_H', 'Distal_match_3_H', 'Distal_match_4_H',\n",
      "       'Distal_match_5_H', 'Distal_match_6_H', 'Proximal_match_-3_L',\n",
      "       'Proximal_match_-2_L', 'Proximal_match_-1_L', 'Proximal_match_0_L',\n",
      "       'Proximal_match_1_L', 'Proximal_match_2_L', 'Proximal_match_3_L',\n",
      "       'Proximal_match_4_L', 'Proximal_match_5_L', 'Proximal_match_6_L',\n",
      "       'Distal_match_-3_L', 'Distal_match_-2_L', 'Distal_match_-1_L',\n",
      "       'Distal_match_0_L', 'Distal_match_1_L', 'Distal_match_2_L',\n",
      "       'Distal_match_3_L', 'Distal_match_4_L', 'Distal_match_5_L',\n",
      "       'Distal_match_6_L', 'Proximal_match_-3_C', 'Proximal_match_-2_C',\n",
      "       'Proximal_match_-1_C', 'Proximal_match_0_C', 'Proximal_match_1_C',\n",
      "       'Proximal_match_2_C', 'Proximal_match_3_C', 'Proximal_match_4_C',\n",
      "       'Proximal_match_5_C', 'Proximal_match_6_C', 'Distal_match_-3_C',\n",
      "       'Distal_match_-2_C', 'Distal_match_-1_C', 'Distal_match_0_C',\n",
      "       'Distal_match_1_C', 'Distal_match_2_C', 'Distal_match_3_C',\n",
      "       'Distal_match_4_C', 'Distal_match_5_C', 'Distal_match_6_C'],\n",
      "      dtype='object')\n",
      "Generating features:  Difference between open and close\n",
      "Shape is now: (4951, 6)\n",
      "~~~\n",
      "Generating features:  Range between high and low\n",
      "Shape is now: (4951, 7)\n",
      "~~~\n",
      "Generating features:  Generic lagged data\n",
      "Generating features:  Diffs over time for lookforward/lookback range\n",
      "Generating features:  Rolling mean for yesterday, today, tomorrow range\n",
      "Your df_scale_with_PCA: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 'PCA1', 'PCA2', 'PCA3', 'PCA4', 'PCA5', 'PCA6', 'PCA7', 'PCA8', 'PCA9', 'PCA10', 'PCA11', 'PCA12']\n",
      "Your df_scale_with_PCA columns are: ['O', 'H', 'L', 'C', 'V', 'change_open_close', 'range_high_low', 'O_std_dev', 'H_std_dev', 'L_std_dev', 'C_std_dev', 'O_rolling_mean', 'H_rolling_mean', 'L_rolling_mean', 'C_rolling_mean', 'change_open_close_rolling_mean', 'rolling_mean_range_HL', 'lag_-3_O', 'lag_-2_O', 'lag_-1_O', 'lag_0_O', 'lag_1_O', 'lag_2_O', 'lag_3_O', 'lag_4_O', 'lag_5_O', 'lag_6_O', 'lag_-3_H', 'lag_-2_H', 'lag_-1_H', 'lag_0_H', 'lag_1_H', 'lag_2_H', 'lag_3_H', 'lag_4_H', 'lag_5_H', 'lag_6_H', 'lag_-3_L', 'lag_-2_L', 'lag_-1_L', 'lag_0_L', 'lag_1_L', 'lag_2_L', 'lag_3_L', 'lag_4_L', 'lag_5_L', 'lag_6_L', 'lag_-3_C', 'lag_-2_C', 'lag_-1_C', 'lag_0_C', 'lag_1_C', 'lag_2_C', 'lag_3_C', 'lag_4_C', 'lag_5_C', 'lag_6_C', 'O_diff_-3', 'H_diff_-3', 'L_diff_-3', 'C_diff_-3', 'change_open_close_diff_-3', 'O_diff_-2', 'H_diff_-2', 'L_diff_-2', 'C_diff_-2', 'change_open_close_diff_-2', 'O_diff_-1', 'H_diff_-1', 'L_diff_-1', 'C_diff_-1', 'change_open_close_diff_-1', 'O_diff_0', 'H_diff_0', 'L_diff_0', 'C_diff_0', 'change_open_close_diff_0', 'O_diff_1', 'H_diff_1', 'L_diff_1', 'C_diff_1', 'change_open_close_diff_1', 'O_diff_2', 'H_diff_2', 'L_diff_2', 'C_diff_2', 'change_open_close_diff_2', 'O_diff_3', 'H_diff_3', 'L_diff_3', 'C_diff_3', 'change_open_close_diff_3', 'O_diff_4', 'H_diff_4', 'L_diff_4', 'C_diff_4', 'change_open_close_diff_4', 'O_diff_5', 'H_diff_5', 'L_diff_5', 'C_diff_5', 'change_open_close_diff_5', 'O_diff_6', 'H_diff_6', 'L_diff_6', 'C_diff_6', 'change_open_close_diff_6', 'O_rolling_mean_diff_-3', 'H_rolling_mean_diff_-3', 'L_rolling_mean_diff_-3', 'C_rolling_mean_diff_-3', 'O_rolling_mean_diff_-2', 'H_rolling_mean_diff_-2', 'L_rolling_mean_diff_-2', 'C_rolling_mean_diff_-2', 'O_rolling_mean_diff_-1', 'H_rolling_mean_diff_-1', 'L_rolling_mean_diff_-1', 'C_rolling_mean_diff_-1', 'O_rolling_mean_diff_0', 'H_rolling_mean_diff_0', 'L_rolling_mean_diff_0', 'C_rolling_mean_diff_0', 'O_rolling_mean_diff_1', 'H_rolling_mean_diff_1', 'L_rolling_mean_diff_1', 'C_rolling_mean_diff_1', 'O_rolling_mean_diff_2', 'H_rolling_mean_diff_2', 'L_rolling_mean_diff_2', 'C_rolling_mean_diff_2', 'PCA1', 'PCA2', 'PCA3', 'PCA4', 'PCA5', 'PCA6', 'PCA7', 'PCA8', 'PCA9', 'PCA10', 'PCA11', 'PCA12']\n",
      "Merging the scaled data and the unscalable data back together with pd.concat: AUDUSD1440.csv (4951, 232)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished: AUDUSD1440.csv (4951, 232)\n",
      "--------------------------------\n",
      "Processing:  GBPJPY1440.csv Number  9  of  11\n",
      "We now have: (38771, 232) rows of data!\n",
      "Reading in Date, OHLCV, Supply/Demand\n",
      "Renaming df_ohlc column headers for clarity\n",
      "Reading in Rectangle data\n",
      "Renaming df_rects column headers for clarity\n",
      "Identifying supply/demand with supply_or_demand func: GBPJPY1440.csv (4978, 12)\n",
      "~~~\n",
      "Identifying zone ends with zone_ender func: GBPJPY1440.csv (4978, 14)\n",
      "~~~\n",
      "Your df_norm columns: Index(['O', 'H', 'L', 'C', 'V'], dtype='object')\n",
      "Your df_non_norm columns: Index(['Epoch Date', 'Supply/Demand', 'Object Name', 'Epoch Date Start',\n",
      "       'Epoch Date End', 'Proximal', 'Distal', 'supply_demand',\n",
      "       'rectangle_here', 'Proximal_match_-3_O', 'Proximal_match_-2_O',\n",
      "       'Proximal_match_-1_O', 'Proximal_match_0_O', 'Proximal_match_1_O',\n",
      "       'Proximal_match_2_O', 'Proximal_match_3_O', 'Proximal_match_4_O',\n",
      "       'Proximal_match_5_O', 'Proximal_match_6_O', 'Distal_match_-3_O',\n",
      "       'Distal_match_-2_O', 'Distal_match_-1_O', 'Distal_match_0_O',\n",
      "       'Distal_match_1_O', 'Distal_match_2_O', 'Distal_match_3_O',\n",
      "       'Distal_match_4_O', 'Distal_match_5_O', 'Distal_match_6_O',\n",
      "       'Proximal_match_-3_H', 'Proximal_match_-2_H', 'Proximal_match_-1_H',\n",
      "       'Proximal_match_0_H', 'Proximal_match_1_H', 'Proximal_match_2_H',\n",
      "       'Proximal_match_3_H', 'Proximal_match_4_H', 'Proximal_match_5_H',\n",
      "       'Proximal_match_6_H', 'Distal_match_-3_H', 'Distal_match_-2_H',\n",
      "       'Distal_match_-1_H', 'Distal_match_0_H', 'Distal_match_1_H',\n",
      "       'Distal_match_2_H', 'Distal_match_3_H', 'Distal_match_4_H',\n",
      "       'Distal_match_5_H', 'Distal_match_6_H', 'Proximal_match_-3_L',\n",
      "       'Proximal_match_-2_L', 'Proximal_match_-1_L', 'Proximal_match_0_L',\n",
      "       'Proximal_match_1_L', 'Proximal_match_2_L', 'Proximal_match_3_L',\n",
      "       'Proximal_match_4_L', 'Proximal_match_5_L', 'Proximal_match_6_L',\n",
      "       'Distal_match_-3_L', 'Distal_match_-2_L', 'Distal_match_-1_L',\n",
      "       'Distal_match_0_L', 'Distal_match_1_L', 'Distal_match_2_L',\n",
      "       'Distal_match_3_L', 'Distal_match_4_L', 'Distal_match_5_L',\n",
      "       'Distal_match_6_L', 'Proximal_match_-3_C', 'Proximal_match_-2_C',\n",
      "       'Proximal_match_-1_C', 'Proximal_match_0_C', 'Proximal_match_1_C',\n",
      "       'Proximal_match_2_C', 'Proximal_match_3_C', 'Proximal_match_4_C',\n",
      "       'Proximal_match_5_C', 'Proximal_match_6_C', 'Distal_match_-3_C',\n",
      "       'Distal_match_-2_C', 'Distal_match_-1_C', 'Distal_match_0_C',\n",
      "       'Distal_match_1_C', 'Distal_match_2_C', 'Distal_match_3_C',\n",
      "       'Distal_match_4_C', 'Distal_match_5_C', 'Distal_match_6_C'],\n",
      "      dtype='object')\n",
      "Generating features:  Difference between open and close\n",
      "Shape is now: (4978, 6)\n",
      "~~~\n",
      "Generating features:  Range between high and low\n",
      "Shape is now: (4978, 7)\n",
      "~~~\n",
      "Generating features:  Generic lagged data\n",
      "Generating features:  Diffs over time for lookforward/lookback range\n",
      "Generating features:  Rolling mean for yesterday, today, tomorrow range\n",
      "Your df_scale_with_PCA: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 'PCA1', 'PCA2', 'PCA3', 'PCA4', 'PCA5', 'PCA6', 'PCA7', 'PCA8', 'PCA9', 'PCA10', 'PCA11', 'PCA12']\n",
      "Your df_scale_with_PCA columns are: ['O', 'H', 'L', 'C', 'V', 'change_open_close', 'range_high_low', 'O_std_dev', 'H_std_dev', 'L_std_dev', 'C_std_dev', 'O_rolling_mean', 'H_rolling_mean', 'L_rolling_mean', 'C_rolling_mean', 'change_open_close_rolling_mean', 'rolling_mean_range_HL', 'lag_-3_O', 'lag_-2_O', 'lag_-1_O', 'lag_0_O', 'lag_1_O', 'lag_2_O', 'lag_3_O', 'lag_4_O', 'lag_5_O', 'lag_6_O', 'lag_-3_H', 'lag_-2_H', 'lag_-1_H', 'lag_0_H', 'lag_1_H', 'lag_2_H', 'lag_3_H', 'lag_4_H', 'lag_5_H', 'lag_6_H', 'lag_-3_L', 'lag_-2_L', 'lag_-1_L', 'lag_0_L', 'lag_1_L', 'lag_2_L', 'lag_3_L', 'lag_4_L', 'lag_5_L', 'lag_6_L', 'lag_-3_C', 'lag_-2_C', 'lag_-1_C', 'lag_0_C', 'lag_1_C', 'lag_2_C', 'lag_3_C', 'lag_4_C', 'lag_5_C', 'lag_6_C', 'O_diff_-3', 'H_diff_-3', 'L_diff_-3', 'C_diff_-3', 'change_open_close_diff_-3', 'O_diff_-2', 'H_diff_-2', 'L_diff_-2', 'C_diff_-2', 'change_open_close_diff_-2', 'O_diff_-1', 'H_diff_-1', 'L_diff_-1', 'C_diff_-1', 'change_open_close_diff_-1', 'O_diff_0', 'H_diff_0', 'L_diff_0', 'C_diff_0', 'change_open_close_diff_0', 'O_diff_1', 'H_diff_1', 'L_diff_1', 'C_diff_1', 'change_open_close_diff_1', 'O_diff_2', 'H_diff_2', 'L_diff_2', 'C_diff_2', 'change_open_close_diff_2', 'O_diff_3', 'H_diff_3', 'L_diff_3', 'C_diff_3', 'change_open_close_diff_3', 'O_diff_4', 'H_diff_4', 'L_diff_4', 'C_diff_4', 'change_open_close_diff_4', 'O_diff_5', 'H_diff_5', 'L_diff_5', 'C_diff_5', 'change_open_close_diff_5', 'O_diff_6', 'H_diff_6', 'L_diff_6', 'C_diff_6', 'change_open_close_diff_6', 'O_rolling_mean_diff_-3', 'H_rolling_mean_diff_-3', 'L_rolling_mean_diff_-3', 'C_rolling_mean_diff_-3', 'O_rolling_mean_diff_-2', 'H_rolling_mean_diff_-2', 'L_rolling_mean_diff_-2', 'C_rolling_mean_diff_-2', 'O_rolling_mean_diff_-1', 'H_rolling_mean_diff_-1', 'L_rolling_mean_diff_-1', 'C_rolling_mean_diff_-1', 'O_rolling_mean_diff_0', 'H_rolling_mean_diff_0', 'L_rolling_mean_diff_0', 'C_rolling_mean_diff_0', 'O_rolling_mean_diff_1', 'H_rolling_mean_diff_1', 'L_rolling_mean_diff_1', 'C_rolling_mean_diff_1', 'O_rolling_mean_diff_2', 'H_rolling_mean_diff_2', 'L_rolling_mean_diff_2', 'C_rolling_mean_diff_2', 'PCA1', 'PCA2', 'PCA3', 'PCA4', 'PCA5', 'PCA6', 'PCA7', 'PCA8', 'PCA9', 'PCA10', 'PCA11', 'PCA12']\n",
      "Merging the scaled data and the unscalable data back together with pd.concat: GBPJPY1440.csv (4978, 232)\n",
      "Finished: GBPJPY1440.csv (4978, 232)\n",
      "--------------------------------\n",
      "Processing:  NZDUSD1440.csv Number  10  of  11\n",
      "We now have: (43749, 232) rows of data!\n",
      "Reading in Date, OHLCV, Supply/Demand\n",
      "Renaming df_ohlc column headers for clarity\n",
      "Reading in Rectangle data\n",
      "Renaming df_rects column headers for clarity\n",
      "Identifying supply/demand with supply_or_demand func: NZDUSD1440.csv (4983, 12)\n",
      "~~~\n",
      "Identifying zone ends with zone_ender func: NZDUSD1440.csv (4983, 14)\n",
      "~~~\n",
      "Your df_norm columns: Index(['O', 'H', 'L', 'C', 'V'], dtype='object')\n",
      "Your df_non_norm columns: Index(['Epoch Date', 'Supply/Demand', 'Object Name', 'Epoch Date Start',\n",
      "       'Epoch Date End', 'Proximal', 'Distal', 'supply_demand',\n",
      "       'rectangle_here', 'Proximal_match_-3_O', 'Proximal_match_-2_O',\n",
      "       'Proximal_match_-1_O', 'Proximal_match_0_O', 'Proximal_match_1_O',\n",
      "       'Proximal_match_2_O', 'Proximal_match_3_O', 'Proximal_match_4_O',\n",
      "       'Proximal_match_5_O', 'Proximal_match_6_O', 'Distal_match_-3_O',\n",
      "       'Distal_match_-2_O', 'Distal_match_-1_O', 'Distal_match_0_O',\n",
      "       'Distal_match_1_O', 'Distal_match_2_O', 'Distal_match_3_O',\n",
      "       'Distal_match_4_O', 'Distal_match_5_O', 'Distal_match_6_O',\n",
      "       'Proximal_match_-3_H', 'Proximal_match_-2_H', 'Proximal_match_-1_H',\n",
      "       'Proximal_match_0_H', 'Proximal_match_1_H', 'Proximal_match_2_H',\n",
      "       'Proximal_match_3_H', 'Proximal_match_4_H', 'Proximal_match_5_H',\n",
      "       'Proximal_match_6_H', 'Distal_match_-3_H', 'Distal_match_-2_H',\n",
      "       'Distal_match_-1_H', 'Distal_match_0_H', 'Distal_match_1_H',\n",
      "       'Distal_match_2_H', 'Distal_match_3_H', 'Distal_match_4_H',\n",
      "       'Distal_match_5_H', 'Distal_match_6_H', 'Proximal_match_-3_L',\n",
      "       'Proximal_match_-2_L', 'Proximal_match_-1_L', 'Proximal_match_0_L',\n",
      "       'Proximal_match_1_L', 'Proximal_match_2_L', 'Proximal_match_3_L',\n",
      "       'Proximal_match_4_L', 'Proximal_match_5_L', 'Proximal_match_6_L',\n",
      "       'Distal_match_-3_L', 'Distal_match_-2_L', 'Distal_match_-1_L',\n",
      "       'Distal_match_0_L', 'Distal_match_1_L', 'Distal_match_2_L',\n",
      "       'Distal_match_3_L', 'Distal_match_4_L', 'Distal_match_5_L',\n",
      "       'Distal_match_6_L', 'Proximal_match_-3_C', 'Proximal_match_-2_C',\n",
      "       'Proximal_match_-1_C', 'Proximal_match_0_C', 'Proximal_match_1_C',\n",
      "       'Proximal_match_2_C', 'Proximal_match_3_C', 'Proximal_match_4_C',\n",
      "       'Proximal_match_5_C', 'Proximal_match_6_C', 'Distal_match_-3_C',\n",
      "       'Distal_match_-2_C', 'Distal_match_-1_C', 'Distal_match_0_C',\n",
      "       'Distal_match_1_C', 'Distal_match_2_C', 'Distal_match_3_C',\n",
      "       'Distal_match_4_C', 'Distal_match_5_C', 'Distal_match_6_C'],\n",
      "      dtype='object')\n",
      "Generating features:  Difference between open and close\n",
      "Shape is now: (4983, 6)\n",
      "~~~\n",
      "Generating features:  Range between high and low\n",
      "Shape is now: (4983, 7)\n",
      "~~~\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating features:  Generic lagged data\n",
      "Generating features:  Diffs over time for lookforward/lookback range\n",
      "Generating features:  Rolling mean for yesterday, today, tomorrow range\n",
      "Your df_scale_with_PCA: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 'PCA1', 'PCA2', 'PCA3', 'PCA4', 'PCA5', 'PCA6', 'PCA7', 'PCA8', 'PCA9', 'PCA10', 'PCA11', 'PCA12']\n",
      "Your df_scale_with_PCA columns are: ['O', 'H', 'L', 'C', 'V', 'change_open_close', 'range_high_low', 'O_std_dev', 'H_std_dev', 'L_std_dev', 'C_std_dev', 'O_rolling_mean', 'H_rolling_mean', 'L_rolling_mean', 'C_rolling_mean', 'change_open_close_rolling_mean', 'rolling_mean_range_HL', 'lag_-3_O', 'lag_-2_O', 'lag_-1_O', 'lag_0_O', 'lag_1_O', 'lag_2_O', 'lag_3_O', 'lag_4_O', 'lag_5_O', 'lag_6_O', 'lag_-3_H', 'lag_-2_H', 'lag_-1_H', 'lag_0_H', 'lag_1_H', 'lag_2_H', 'lag_3_H', 'lag_4_H', 'lag_5_H', 'lag_6_H', 'lag_-3_L', 'lag_-2_L', 'lag_-1_L', 'lag_0_L', 'lag_1_L', 'lag_2_L', 'lag_3_L', 'lag_4_L', 'lag_5_L', 'lag_6_L', 'lag_-3_C', 'lag_-2_C', 'lag_-1_C', 'lag_0_C', 'lag_1_C', 'lag_2_C', 'lag_3_C', 'lag_4_C', 'lag_5_C', 'lag_6_C', 'O_diff_-3', 'H_diff_-3', 'L_diff_-3', 'C_diff_-3', 'change_open_close_diff_-3', 'O_diff_-2', 'H_diff_-2', 'L_diff_-2', 'C_diff_-2', 'change_open_close_diff_-2', 'O_diff_-1', 'H_diff_-1', 'L_diff_-1', 'C_diff_-1', 'change_open_close_diff_-1', 'O_diff_0', 'H_diff_0', 'L_diff_0', 'C_diff_0', 'change_open_close_diff_0', 'O_diff_1', 'H_diff_1', 'L_diff_1', 'C_diff_1', 'change_open_close_diff_1', 'O_diff_2', 'H_diff_2', 'L_diff_2', 'C_diff_2', 'change_open_close_diff_2', 'O_diff_3', 'H_diff_3', 'L_diff_3', 'C_diff_3', 'change_open_close_diff_3', 'O_diff_4', 'H_diff_4', 'L_diff_4', 'C_diff_4', 'change_open_close_diff_4', 'O_diff_5', 'H_diff_5', 'L_diff_5', 'C_diff_5', 'change_open_close_diff_5', 'O_diff_6', 'H_diff_6', 'L_diff_6', 'C_diff_6', 'change_open_close_diff_6', 'O_rolling_mean_diff_-3', 'H_rolling_mean_diff_-3', 'L_rolling_mean_diff_-3', 'C_rolling_mean_diff_-3', 'O_rolling_mean_diff_-2', 'H_rolling_mean_diff_-2', 'L_rolling_mean_diff_-2', 'C_rolling_mean_diff_-2', 'O_rolling_mean_diff_-1', 'H_rolling_mean_diff_-1', 'L_rolling_mean_diff_-1', 'C_rolling_mean_diff_-1', 'O_rolling_mean_diff_0', 'H_rolling_mean_diff_0', 'L_rolling_mean_diff_0', 'C_rolling_mean_diff_0', 'O_rolling_mean_diff_1', 'H_rolling_mean_diff_1', 'L_rolling_mean_diff_1', 'C_rolling_mean_diff_1', 'O_rolling_mean_diff_2', 'H_rolling_mean_diff_2', 'L_rolling_mean_diff_2', 'C_rolling_mean_diff_2', 'PCA1', 'PCA2', 'PCA3', 'PCA4', 'PCA5', 'PCA6', 'PCA7', 'PCA8', 'PCA9', 'PCA10', 'PCA11', 'PCA12']\n",
      "Merging the scaled data and the unscalable data back together with pd.concat: NZDUSD1440.csv (4983, 232)\n",
      "Finished: NZDUSD1440.csv (4983, 232)\n",
      "--------------------------------\n",
      "Processing:  EURUSD240.csv Number  11  of  11\n",
      "We now have: (48732, 232) rows of data!\n",
      "Reading in Date, OHLCV, Supply/Demand\n",
      "Renaming df_ohlc column headers for clarity\n",
      "Reading in Rectangle data\n",
      "Renaming df_rects column headers for clarity\n",
      "Identifying supply/demand with supply_or_demand func: EURUSD240.csv (8749, 12)\n",
      "~~~\n",
      "Identifying zone ends with zone_ender func: EURUSD240.csv (8749, 14)\n",
      "~~~\n",
      "Your df_norm columns: Index(['O', 'H', 'L', 'C', 'V'], dtype='object')\n",
      "Your df_non_norm columns: Index(['Epoch Date', 'Supply/Demand', 'Object Name', 'Epoch Date Start',\n",
      "       'Epoch Date End', 'Proximal', 'Distal', 'supply_demand',\n",
      "       'rectangle_here', 'Proximal_match_-3_O', 'Proximal_match_-2_O',\n",
      "       'Proximal_match_-1_O', 'Proximal_match_0_O', 'Proximal_match_1_O',\n",
      "       'Proximal_match_2_O', 'Proximal_match_3_O', 'Proximal_match_4_O',\n",
      "       'Proximal_match_5_O', 'Proximal_match_6_O', 'Distal_match_-3_O',\n",
      "       'Distal_match_-2_O', 'Distal_match_-1_O', 'Distal_match_0_O',\n",
      "       'Distal_match_1_O', 'Distal_match_2_O', 'Distal_match_3_O',\n",
      "       'Distal_match_4_O', 'Distal_match_5_O', 'Distal_match_6_O',\n",
      "       'Proximal_match_-3_H', 'Proximal_match_-2_H', 'Proximal_match_-1_H',\n",
      "       'Proximal_match_0_H', 'Proximal_match_1_H', 'Proximal_match_2_H',\n",
      "       'Proximal_match_3_H', 'Proximal_match_4_H', 'Proximal_match_5_H',\n",
      "       'Proximal_match_6_H', 'Distal_match_-3_H', 'Distal_match_-2_H',\n",
      "       'Distal_match_-1_H', 'Distal_match_0_H', 'Distal_match_1_H',\n",
      "       'Distal_match_2_H', 'Distal_match_3_H', 'Distal_match_4_H',\n",
      "       'Distal_match_5_H', 'Distal_match_6_H', 'Proximal_match_-3_L',\n",
      "       'Proximal_match_-2_L', 'Proximal_match_-1_L', 'Proximal_match_0_L',\n",
      "       'Proximal_match_1_L', 'Proximal_match_2_L', 'Proximal_match_3_L',\n",
      "       'Proximal_match_4_L', 'Proximal_match_5_L', 'Proximal_match_6_L',\n",
      "       'Distal_match_-3_L', 'Distal_match_-2_L', 'Distal_match_-1_L',\n",
      "       'Distal_match_0_L', 'Distal_match_1_L', 'Distal_match_2_L',\n",
      "       'Distal_match_3_L', 'Distal_match_4_L', 'Distal_match_5_L',\n",
      "       'Distal_match_6_L', 'Proximal_match_-3_C', 'Proximal_match_-2_C',\n",
      "       'Proximal_match_-1_C', 'Proximal_match_0_C', 'Proximal_match_1_C',\n",
      "       'Proximal_match_2_C', 'Proximal_match_3_C', 'Proximal_match_4_C',\n",
      "       'Proximal_match_5_C', 'Proximal_match_6_C', 'Distal_match_-3_C',\n",
      "       'Distal_match_-2_C', 'Distal_match_-1_C', 'Distal_match_0_C',\n",
      "       'Distal_match_1_C', 'Distal_match_2_C', 'Distal_match_3_C',\n",
      "       'Distal_match_4_C', 'Distal_match_5_C', 'Distal_match_6_C'],\n",
      "      dtype='object')\n",
      "Generating features:  Difference between open and close\n",
      "Shape is now: (8749, 6)\n",
      "~~~\n",
      "Generating features:  Range between high and low\n",
      "Shape is now: (8749, 7)\n",
      "~~~\n",
      "Generating features:  Generic lagged data\n",
      "Generating features:  Diffs over time for lookforward/lookback range\n",
      "Generating features:  Rolling mean for yesterday, today, tomorrow range\n",
      "Your df_scale_with_PCA: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 'PCA1', 'PCA2', 'PCA3', 'PCA4', 'PCA5', 'PCA6', 'PCA7', 'PCA8', 'PCA9', 'PCA10', 'PCA11', 'PCA12']\n",
      "Your df_scale_with_PCA columns are: ['O', 'H', 'L', 'C', 'V', 'change_open_close', 'range_high_low', 'O_std_dev', 'H_std_dev', 'L_std_dev', 'C_std_dev', 'O_rolling_mean', 'H_rolling_mean', 'L_rolling_mean', 'C_rolling_mean', 'change_open_close_rolling_mean', 'rolling_mean_range_HL', 'lag_-3_O', 'lag_-2_O', 'lag_-1_O', 'lag_0_O', 'lag_1_O', 'lag_2_O', 'lag_3_O', 'lag_4_O', 'lag_5_O', 'lag_6_O', 'lag_-3_H', 'lag_-2_H', 'lag_-1_H', 'lag_0_H', 'lag_1_H', 'lag_2_H', 'lag_3_H', 'lag_4_H', 'lag_5_H', 'lag_6_H', 'lag_-3_L', 'lag_-2_L', 'lag_-1_L', 'lag_0_L', 'lag_1_L', 'lag_2_L', 'lag_3_L', 'lag_4_L', 'lag_5_L', 'lag_6_L', 'lag_-3_C', 'lag_-2_C', 'lag_-1_C', 'lag_0_C', 'lag_1_C', 'lag_2_C', 'lag_3_C', 'lag_4_C', 'lag_5_C', 'lag_6_C', 'O_diff_-3', 'H_diff_-3', 'L_diff_-3', 'C_diff_-3', 'change_open_close_diff_-3', 'O_diff_-2', 'H_diff_-2', 'L_diff_-2', 'C_diff_-2', 'change_open_close_diff_-2', 'O_diff_-1', 'H_diff_-1', 'L_diff_-1', 'C_diff_-1', 'change_open_close_diff_-1', 'O_diff_0', 'H_diff_0', 'L_diff_0', 'C_diff_0', 'change_open_close_diff_0', 'O_diff_1', 'H_diff_1', 'L_diff_1', 'C_diff_1', 'change_open_close_diff_1', 'O_diff_2', 'H_diff_2', 'L_diff_2', 'C_diff_2', 'change_open_close_diff_2', 'O_diff_3', 'H_diff_3', 'L_diff_3', 'C_diff_3', 'change_open_close_diff_3', 'O_diff_4', 'H_diff_4', 'L_diff_4', 'C_diff_4', 'change_open_close_diff_4', 'O_diff_5', 'H_diff_5', 'L_diff_5', 'C_diff_5', 'change_open_close_diff_5', 'O_diff_6', 'H_diff_6', 'L_diff_6', 'C_diff_6', 'change_open_close_diff_6', 'O_rolling_mean_diff_-3', 'H_rolling_mean_diff_-3', 'L_rolling_mean_diff_-3', 'C_rolling_mean_diff_-3', 'O_rolling_mean_diff_-2', 'H_rolling_mean_diff_-2', 'L_rolling_mean_diff_-2', 'C_rolling_mean_diff_-2', 'O_rolling_mean_diff_-1', 'H_rolling_mean_diff_-1', 'L_rolling_mean_diff_-1', 'C_rolling_mean_diff_-1', 'O_rolling_mean_diff_0', 'H_rolling_mean_diff_0', 'L_rolling_mean_diff_0', 'C_rolling_mean_diff_0', 'O_rolling_mean_diff_1', 'H_rolling_mean_diff_1', 'L_rolling_mean_diff_1', 'C_rolling_mean_diff_1', 'O_rolling_mean_diff_2', 'H_rolling_mean_diff_2', 'L_rolling_mean_diff_2', 'C_rolling_mean_diff_2', 'PCA1', 'PCA2', 'PCA3', 'PCA4', 'PCA5', 'PCA6', 'PCA7', 'PCA8', 'PCA9', 'PCA10', 'PCA11', 'PCA12']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Merging the scaled data and the unscalable data back together with pd.concat: EURUSD240.csv (8749, 232)\n",
      "Finished: EURUSD240.csv (8749, 232)\n",
      "--------------------------------\n",
      "Finished loading data! You'll probably still want to remove some columns though\n"
     ]
    }
   ],
   "source": [
    "# Create list of target csvs\n",
    "data = [\"EURJPY1440.csv\", \"EURGBP1440.csv\",\"USDCAD1440.csv\",\"GBPUSD1440.csv\",\\\n",
    "        \"EURUSD14402.csv\",\"USDCHF1440.csv\",\"EURAUD14402.csv\",\"AUDUSD1440.csv\",\\\n",
    "               \"GBPJPY1440.csv\", \"NZDUSD1440.csv\", \"EURUSD240.csv\", \n",
    "#         'indi_EURCAD_15.csv', \n",
    "#        'indi_USDCAD_15.csv','indi_USDJPY_15.csv', 'indi_USDJPY_60.csv' \n",
    "       ]\n",
    "\n",
    "# allows us to easily modify how many days ahead and before we look:\n",
    "lookforward = 3 # how many days we look forward\n",
    "lookback = 7 # how many days we look back\n",
    "\n",
    "        \n",
    "# Choose features to be used in feature generation function\n",
    "feature_generation_channels = [\"O\", \"H\", \"L\", \"C\"] \n",
    "\n",
    "X, y, df_ohlc_and_rectangles, groups,\\\n",
    "groups_count, scalers, groups_dict,\\\n",
    "scaled_columns, df_data_unscaled,\\\n",
    "y_rects, proximal_columns, distal_columns = data_processing.prepare_data(data, \n",
    "                                                                 lookforward, \n",
    "                                                                 lookback,\n",
    "                                                                 feature_generation_channels,\n",
    "                                                                 lag_data=1,\n",
    "                                                                 change_open_close=1, \n",
    "                                                                 range_high_low=1,\n",
    "                                                                 rolling_mean_range_HL=1,\n",
    "                                                                 range_high_close=0,\n",
    "                                                                 std_dev=1,\n",
    "                                                                 rolling_mean=1,\n",
    "                                                                 change_open_close_shift=0,\n",
    "                                                                 range_high_low_shift=0,\n",
    "                                                                 range_high_close_shift=0,\n",
    "                                                                 diff_shift=1,\n",
    "                                                                 rolling_mean_shift=1,\n",
    "                                                                 std_dev_shift=0,\n",
    "                                                                 center=False\n",
    "                                                                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Save data into backup X, y so we don't have to reload it \n",
    "\n",
    "X_backup = X\n",
    "y_backup = y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = X_backup\n",
    "y = y_backup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "labels_distal = [col for col in list(y) if col.startswith('Distal_')]\n",
    "labels_proximal = [col for col in list(y) if col.startswith('Proximal_')]\n",
    "labels_rectangle_here = [col for col in list(y) if col.startswith('rectangle_')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/site-packages/ipykernel_launcher.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  # This is added back by InteractiveShellApp.init_path()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7316, 4)\n",
      "(7316, 129)\n"
     ]
    }
   ],
   "source": [
    "# Make list of features and label column names\n",
    "features = [col for col in list(X)]\n",
    "labels = labels_proximal\n",
    "reduced_match_list = ['Proximal_match_1_C', \n",
    "                      'Proximal_match_0_C', \n",
    "                      'Proximal_match_0_O', \n",
    "                      'Proximal_match_-1_O']\n",
    "\n",
    "# Select only rows that contain zones, eliminate minority class elements (only about 4% of data)\n",
    "df_zones = df_ohlc_and_rectangles.loc[df_ohlc_and_rectangles['rectangle_here'] == 1]\n",
    "df_zones['sum'] = df_zones[reduced_match_list].sum(axis=1)\n",
    "df_zones = df_zones[df_zones['sum'] != 0]\n",
    "\n",
    "# Split out the new df into features and labels\n",
    "df_X = df_zones[features]\n",
    "df_y = df_zones[reduced_match_list]\n",
    "\n",
    "# Drop features from X\n",
    "features_to_remove = ['Epoch Date', 'Supply/Demand', 'Object Name', 'Epoch Date Start', 'L_diff_0', 'O_diff_0',\n",
    "                      'Epoch Date End', 'Proximal', 'Distal', 'change', 'V_diff_0', 'C_diff_0', 'H_diff_0',\n",
    "                      'O', 'H', 'L', 'C', \n",
    "                      'csv_origin_tag', 'range_high_close_range_0', 'change_open_close', 'range_high_close', \n",
    "                      'rectangle_here', 'supply_demand', 'group']\n",
    "\n",
    "df_X = data_processing.drop_non_features(df_X, features_to_remove, zero_columns=1)\n",
    "df_y = data_processing.drop_non_features(df_y, ['Proximal'], zero_columns=1)\n",
    "\n",
    "# Clean up duplicate labels (i.e. where multiple matches were found)\n",
    "df_y = df_y.apply(lambda x:x.drop_duplicates(), axis=1).fillna(False)\n",
    "\n",
    "\n",
    "print(df_y.shape)\n",
    "print(df_X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Resort the DF and add what we think are the more important features to the front of the columns list\n",
    "# Also, this removes all the plain 'lag' data, which we think has no meaning\n",
    "X_cols_resort = ['change_open_close_diff_-1',  'C_rolling_mean_diff_-1', 'O_rolling_mean_diff_1', 'H_diff_1', 'C_diff_1', 'change_open_close_diff_1', 'H_diff_2', 'C_diff_2', 'change_open_close_diff_2', 'H_diff_3', 'C_diff_3','V', 'range_high_low', 'O_std_dev', 'H_std_dev', 'L_std_dev', 'C_std_dev', 'O_rolling_mean', 'H_rolling_mean', 'L_rolling_mean', 'C_rolling_mean', 'change_open_close_rolling_mean', 'rolling_mean_range_HL', 'O_diff_-3', 'H_diff_-3', 'L_diff_-3', 'C_diff_-3', 'change_open_close_diff_-3', 'O_diff_-2', 'H_diff_-2', 'L_diff_-2', 'C_diff_-2', 'change_open_close_diff_-2', 'O_diff_-1', 'H_diff_-1', 'L_diff_-1', 'C_diff_-1', 'change_open_close_diff_3', 'O_diff_4', 'H_diff_4', 'L_diff_4', 'C_diff_4', 'change_open_close_diff_4', 'O_diff_5', 'H_diff_5', 'L_diff_5', 'C_diff_5', 'change_open_close_diff_5', 'O_diff_6', 'H_diff_6', 'L_diff_6', 'C_diff_6', 'change_open_close_diff_6', 'O_rolling_mean_diff_-3', 'H_rolling_mean_diff_-3', 'L_rolling_mean_diff_-3', 'C_rolling_mean_diff_-3', 'O_rolling_mean_diff_-2', 'H_rolling_mean_diff_-2', 'L_rolling_mean_diff_-2', 'C_rolling_mean_diff_-2', 'O_rolling_mean_diff_-1', 'H_rolling_mean_diff_-1', 'L_rolling_mean_diff_-1', 'H_rolling_mean_diff_1', 'L_rolling_mean_diff_1', 'C_rolling_mean_diff_1', 'O_rolling_mean_diff_2', 'H_rolling_mean_diff_2', 'L_rolling_mean_diff_2', 'C_rolling_mean_diff_2', 'O_diff_1','L_diff_1','O_diff_2','L_diff_2','O_diff_3','L_diff_3', 'PCA1', 'PCA2', 'PCA3', 'PCA4', 'PCA5', 'PCA6', 'PCA7', 'PCA8', 'PCA9', 'PCA10', 'PCA11',]\n",
    "\n",
    "df_X = df_X[X_cols_resort]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "88\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/output/data_processing.py:865: UserWarning: Update your `Model` call to the Keras 2 API: `Model(outputs=Tensor(\"de..., inputs=Tensor(\"in...)`\n",
      "  autoencoder = Model(input = input_dim, output = decoded4)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 3292 samples, validate on 366 samples\n",
      "Epoch 1/20\n",
      "3292/3292 [==============================] - 0s - loss: 0.6926 - val_loss: 0.6923\n",
      "Epoch 2/20\n",
      "3292/3292 [==============================] - 0s - loss: 0.6921 - val_loss: 0.6918\n",
      "Epoch 3/20\n",
      "3292/3292 [==============================] - 0s - loss: 0.6916 - val_loss: 0.6913\n",
      "Epoch 4/20\n",
      "3292/3292 [==============================] - 0s - loss: 0.6911 - val_loss: 0.6908\n",
      "Epoch 5/20\n",
      "3292/3292 [==============================] - 0s - loss: 0.6906 - val_loss: 0.6903\n",
      "Epoch 6/20\n",
      "3292/3292 [==============================] - 0s - loss: 0.6900 - val_loss: 0.6897\n",
      "Epoch 7/20\n",
      "3292/3292 [==============================] - 0s - loss: 0.6894 - val_loss: 0.6890\n",
      "Epoch 8/20\n",
      "3292/3292 [==============================] - 0s - loss: 0.6888 - val_loss: 0.6883\n",
      "Epoch 9/20\n",
      "3292/3292 [==============================] - 0s - loss: 0.6880 - val_loss: 0.6875\n",
      "Epoch 10/20\n",
      "3292/3292 [==============================] - 0s - loss: 0.6872 - val_loss: 0.6866\n",
      "Epoch 11/20\n",
      "3292/3292 [==============================] - 0s - loss: 0.6863 - val_loss: 0.6856\n",
      "Epoch 12/20\n",
      "3292/3292 [==============================] - 0s - loss: 0.6852 - val_loss: 0.6844\n",
      "Epoch 13/20\n",
      "3292/3292 [==============================] - 0s - loss: 0.6839 - val_loss: 0.6831\n",
      "Epoch 14/20\n",
      "3292/3292 [==============================] - 0s - loss: 0.6825 - val_loss: 0.6815\n",
      "Epoch 15/20\n",
      "3292/3292 [==============================] - 0s - loss: 0.6809 - val_loss: 0.6798\n",
      "Epoch 16/20\n",
      "3292/3292 [==============================] - 0s - loss: 0.6790 - val_loss: 0.6778\n",
      "Epoch 17/20\n",
      "3292/3292 [==============================] - 0s - loss: 0.6769 - val_loss: 0.6755\n",
      "Epoch 18/20\n",
      "3292/3292 [==============================] - 0s - loss: 0.6746 - val_loss: 0.6730\n",
      "Epoch 19/20\n",
      "3292/3292 [==============================] - 0s - loss: 0.6721 - val_loss: 0.6704\n",
      "Epoch 20/20\n",
      "3292/3292 [==============================] - 0s - loss: 0.6694 - val_loss: 0.6676\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/output/data_processing.py:870: UserWarning: Update your `Model` call to the Keras 2 API: `Model(outputs=Tensor(\"de..., inputs=Tensor(\"in...)`\n",
      "  encoder = Model(input = input_dim, output = encoded4)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7316, 3)\n",
      "Original n of features: 88\n",
      "autoencoded_features: 3\n"
     ]
    }
   ],
   "source": [
    "# Create autoencoded features\n",
    "X_ae = data_processing.autoencode(df_X, df_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Add together the main features and the autoencoder features\n",
    "X_ = pd.concat([df_X.reset_index(drop=True), X_ae.reset_index(drop=True)], axis=1, ignore_index=True)  \n",
    "X_.columns = list(df_X) + list(X_ae)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create a list to re-sort with again, putting our AE features at the front\n",
    "X__cols_resort = list(X_ae) + ['change_open_close_diff_-1',  'C_rolling_mean_diff_-1', 'O_rolling_mean_diff_1', 'H_diff_1', 'C_diff_1', 'change_open_close_diff_1', 'H_diff_2', 'C_diff_2', 'change_open_close_diff_2', 'H_diff_3', 'C_diff_3','V', 'range_high_low', 'O_std_dev', 'H_std_dev', 'L_std_dev', 'C_std_dev', 'O_rolling_mean', 'H_rolling_mean', 'L_rolling_mean', 'C_rolling_mean', 'change_open_close_rolling_mean', 'rolling_mean_range_HL', 'O_diff_-3', 'H_diff_-3', 'L_diff_-3', 'C_diff_-3', 'change_open_close_diff_-3', 'O_diff_-2', 'H_diff_-2', 'L_diff_-2', 'C_diff_-2', 'change_open_close_diff_-2', 'O_diff_-1', 'H_diff_-1', 'L_diff_-1', 'C_diff_-1', 'change_open_close_diff_3', 'O_diff_4', 'H_diff_4', 'L_diff_4', 'C_diff_4', 'change_open_close_diff_4', 'O_diff_5', 'H_diff_5', 'L_diff_5', 'C_diff_5', 'change_open_close_diff_5', 'O_diff_6', 'H_diff_6', 'L_diff_6', 'C_diff_6', 'change_open_close_diff_6', 'O_rolling_mean_diff_-3', 'H_rolling_mean_diff_-3', 'L_rolling_mean_diff_-3', 'C_rolling_mean_diff_-3', 'O_rolling_mean_diff_-2', 'H_rolling_mean_diff_-2', 'L_rolling_mean_diff_-2', 'C_rolling_mean_diff_-2', 'O_rolling_mean_diff_-1', 'H_rolling_mean_diff_-1', 'L_rolling_mean_diff_-1', 'H_rolling_mean_diff_1', 'L_rolling_mean_diff_1', 'C_rolling_mean_diff_1', 'O_rolling_mean_diff_2', 'H_rolling_mean_diff_2', 'L_rolling_mean_diff_2', 'C_rolling_mean_diff_2', 'O_diff_1','L_diff_1','O_diff_2','L_diff_2','O_diff_3','L_diff_3', 'PCA1', 'PCA2', 'PCA3', 'PCA4', 'PCA5', 'PCA6', 'PCA7', 'PCA8', 'PCA9', 'PCA10', 'PCA11',]\n",
    "X_ = X_[X__cols_resort]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create train/test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_, df_y, test_size=0.1)\n",
    "\n",
    "# Create validation split from train split\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X_train, y_train, test_size=0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X:  (6254, 91, 1)\n",
      "X:  <class 'numpy.ndarray'>\n",
      "X:  (330, 91, 1)\n",
      "X:  <class 'numpy.ndarray'>\n",
      "X:  (732, 91, 1)\n",
      "X:  <class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "# Stack original X_train to 3dim for conv net\n",
    "X_train = data_processing.X_to_Conv1D_arrays(X_train)\n",
    "X_valid = data_processing.X_to_Conv1D_arrays(X_valid)\n",
    "X_test = data_processing.X_to_Conv1D_arrays(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6254, 91, 1) (330, 91, 1) (732, 91, 1) (6254, 4) (330, 4) (732, 4)\n"
     ]
    }
   ],
   "source": [
    "print (X_train.shape, X_valid.shape, X_test.shape, y_train.shape, y_valid.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LSTM for Proximal_match"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create generators and define batch_size and other hyperparams\n",
    "batch_size = 64\n",
    "\n",
    "# Create generators\n",
    "train_gen = make_keras_generators.train_generator(X_train, y_train.values, batch_size)\n",
    "valid_gen = make_keras_generators.valid_generator(X_valid, y_valid.values, batch_size)\n",
    "\n",
    "input_shape = X_train.shape[1:3]\n",
    "output_shape = df_y.shape[1]\n",
    "validation_steps = int(len(X_valid)/batch_size)+1\n",
    "steps_per_epoch = int(len(X_train)/batch_size)+1\n",
    "epochs = 15\n",
    "\n",
    "validation_steps = int(len(X_valid)/batch_size)+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mc_filepath = 'proximal-AE-july6-325pm-LSTM-{epoch:02d}-{val_fbeta_score:.2f}.h5'\n",
    "mc = ModelCheckpoint(mc_filepath, \n",
    "                     monitor='val_fbeta_score', \n",
    "                     verbose=1, \n",
    "                     #save_weights_only=True,\n",
    "                     period=10, mode='max',\n",
    "                     save_best_only=False)\n",
    "\n",
    "rlop = ReduceLROnPlateau(\n",
    "                    monitor='val_loss', \n",
    "                    mode='min',\n",
    "                    factor=0.6,\n",
    "                    patience=10, \n",
    "                    min_lr=0.00001,\n",
    "                    verbose=1,\n",
    "                        )\n",
    "\n",
    "es = EarlyStopping(\n",
    "        monitor='val_loss',\n",
    "        #min_delta=0.01,\n",
    "        mode='min',\n",
    "        patience=50,\n",
    "        verbose=1)\n",
    "\n",
    "\n",
    "\n",
    "callbacks = [ es, rlop, mc,]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define the proximal_match model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Use this cell if we want to start from scratch\n",
    "proximal_model = Sequential()\n",
    "proximal_model.add(Bidirectional(LSTM(128, return_sequences=False,\n",
    "                                     recurrent_dropout=0.3, dropout=0.3), \n",
    "                                 input_shape=input_shape, \n",
    "                                 batch_input_shape=(None, X_train.shape[1], X_train.shape[2])))\n",
    "proximal_model.add(Dropout(0.3))\n",
    "proximal_model.add(Dense(output_shape, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "proximal_model = load_model('proximal-AE-july6-131pm-LSTM-83-0.84.h5', custom_objects={'AdamWithWeightnorm': AdamWithWeightnorm, 'fbeta_score': custom_metrics.fbeta_score, 'recall': custom_metrics.recall, 'precision': custom_metrics.precision})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "proximal_model.compile(optimizer=AdamWithWeightnorm(0.0025), \n",
    "              loss='categorical_crossentropy',\n",
    "                metrics = ['accuracy', \n",
    "                           custom_metrics.fbeta_score,\n",
    "                           custom_metrics.recall,\n",
    "                          custom_metrics.precision,]\n",
    "            )\n",
    "\n",
    "\n",
    "history = proximal_model.fit_generator(\n",
    "                    train_gen,\n",
    "                    steps_per_epoch=int(len(X_train)/batch_size)+1,\n",
    "                    epochs=epochs,\n",
    "                    verbose=1,\n",
    "                    callbacks=callbacks,\n",
    "                    validation_data = valid_gen,\n",
    "                    #class_weight = class_weight,\n",
    "                    validation_steps = validation_steps\n",
    "                   )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "proximal_model.save('proximal-LSTM-07.06.17.324pm.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your classification report: \n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.00      0.00      0.00         0\n",
      "          1       0.97      0.92      0.95       347\n",
      "          2       0.79      0.93      0.86       321\n",
      "          3       0.33      0.12      0.18        64\n",
      "\n",
      "avg / total       0.84      0.86      0.84       732\n",
      "\n",
      "-----------------------------\n",
      "Log loss: 0.322061272654\n",
      "F1 weighted: 0.840573676009\n",
      "F1 macro: 0.496426650273\n",
      "F1 micro: 0.857923497268\n",
      "Accuracy score: 0.857923497268\n",
      "Hamming Loss: 0.07103825136612021\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/site-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/usr/local/lib/python3.5/site-packages/sklearn/metrics/classification.py:1115: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "/usr/local/lib/python3.5/site-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/usr/local/lib/python3.5/site-packages/sklearn/metrics/classification.py:1115: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "preds, y_pred_proba = model_performance_evaluation.eval(proximal_model, \n",
    "                                                        X_test, \n",
    "                                                        y_test.values,\n",
    "                                                        #weights='rectangle_here-Conv1D-19-0.61.h5',\n",
    "                                                        batch_size=512, temperature=0.65, binary=0, sequential=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'history' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-24-1438fb2c8acc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfigsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m12\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m12\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# list all data in history\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;31m# summarize history for accuracy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'fbeta_score'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'history' is not defined"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f0e167fbdd8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.set_context(\"paper\", font_scale=2)\n",
    "plt.figure(figsize=(12, 12))\n",
    "# list all data in history\n",
    "print(history.history.keys())\n",
    "# summarize history for accuracy\n",
    "plt.plot(history.history['fbeta_score'])\n",
    "plt.plot(history.history['val_fbeta_score'])\n",
    "plt.title('fbeta_score')\n",
    "plt.ylabel('fbeta_score')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'val'], loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# summarize history for loss\n",
    "fig_loss = plt.figure(figsize=(10, 10))\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "# show lr changing\n",
    "sns.set_context(\"paper\", font_scale=2)\n",
    "plt.figure(figsize=(12, 12))\n",
    "# list all data in history\n",
    "print(history.history.keys())\n",
    "# summarize history for accuracy\n",
    "plt.plot(history.history['lr'])\n",
    "#plt.plot(history.history['val_fbeta_score'])\n",
    "plt.title('learning rate')\n",
    "plt.ylabel('lr')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'val'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make predictions on raw data and visualize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = ['floyd-ignore/USDCAD1440.csv']\n",
    "\n",
    "# allows us to easily modify how many days ahead and before we look:\n",
    "lookforward = 6 # how many days we look forward\n",
    "lookback = 6 # how many days we look back\n",
    "\n",
    "        \n",
    "# Choose features to be used in feature generation function\n",
    "feature_generation_channels = [\"O\", \"H\", \"L\", \"C\", \"V\"] \n",
    "\n",
    "X, y, df_ohlc_and_rectangles, groups,\\\n",
    "groups_count, scalers, groups_dict,\\\n",
    "scaled_columns, df_data_unscaled,\\\n",
    "y_rects, proximal_columns, distal_columns = data_processing.prepare_data(data, \n",
    "                                                                 lookforward, \n",
    "                                                                 lookback,\n",
    "                                                                 feature_generation_channels,\n",
    "                                                                 lag_data=1,\n",
    "                                                                 change_open_close=1, \n",
    "                                                                 range_high_low=1,\n",
    "                                                                 rolling_mean_range_HL=1,\n",
    "                                                                 range_high_close=1,\n",
    "                                                                 std_dev=1,\n",
    "                                                                 rolling_mean=1,\n",
    "                                                                 change_open_close_shift=1,\n",
    "                                                                 range_high_low_shift=0,\n",
    "                                                                 range_high_close_shift=1,\n",
    "                                                                 diff_shift=1,\n",
    "                                                                 rolling_mean_shift=1,\n",
    "                                                                 std_dev_shift=1,\n",
    "                                                                 center=True\n",
    "                                                                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Make list of features and label column names\n",
    "features = [col for col in list(X)]\n",
    "labels_distal = [col for col in list(df_ohlc_and_rectangles) if col.startswith('Distal_')]\n",
    "labels_proximal = [col for col in list(df_ohlc_and_rectangles) if col.startswith('Proximal_')]\n",
    "labels = labels_distal + labels_proximal\n",
    "\n",
    "# Select only rows that contain zones\n",
    "#df_zones = df_ohlc_and_rectangles.loc[df_ohlc_and_rectangles['rectangle_here'] == 1]\n",
    "df_ohlc = df_ohlc_and_rectangles\n",
    "\n",
    "# Split out the new df into features and labels\n",
    "#df_X = df_zones[features]\n",
    "#df_y = df_zones[labels]\n",
    "df_X = df_ohlc_and_rectangles[features]\n",
    "df_y_proximal = df_ohlc_and_rectangles[labels_proximal]\n",
    "df_y_distal = df_ohlc_and_rectangles[labels_distal]\n",
    "\n",
    "\n",
    "%aimport data_processing\n",
    "\n",
    "# Drop features from X\n",
    "features_to_remove = ['Epoch Date', 'Supply/Demand', 'Object Name', 'Epoch Date Start', 'L_diff_0', 'O_diff_0',\n",
    "                      'Epoch Date End', 'Proximal', 'Distal', 'change', 'V_diff_0', 'C_diff_0', 'H_diff_0',\n",
    "                      #'O', 'H', 'L', 'C', \n",
    "                      'csv_origin_tag', 'range_high_close_range_0', 'change_open_close', 'range_high_close', \n",
    "                      #'rectangle_here', \n",
    "                      'supply_demand', 'group']\n",
    "\n",
    "\n",
    "df_X = data_processing.drop_non_features(df_X, features_to_remove, zero_columns=1)\n",
    "df_y_proximal = data_processing.drop_non_features(df_y_proximal, ['Proximal'], zero_columns=1)\n",
    "df_y_distal = data_processing.drop_non_features(df_y_distal, ['Distal'], zero_columns=1)\n",
    "\n",
    "df_y_proximal = df_y_proximal.apply(lambda x:x.drop_duplicates(), axis=1).fillna(False)\n",
    "df_y_distal = df_y_distal.apply(lambda x:x.drop_duplicates(), axis=1).fillna(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lag_cols = [col for col in list(df_X) if col.startswith('lag')]\n",
    "ohlc_cols = ['O', 'H', 'L', 'C', 'V'] + lag_cols\n",
    "\n",
    "df_X_ohlc = df_X[ohlc_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# For lining up predictions and data\n",
    "#df_predictions = pd.DataFrame(preds.astype(int))\n",
    "df_y = pd.concat([df_y_proximal, \n",
    "                          df_y_distal], \n",
    "                         axis=1, \n",
    "                         ignore_index=True)  \n",
    "df_y.columns = list(df_y_proximal) + list(df_y_distal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Add together the raw ohlc data and the y labels\n",
    "df_OHLC = pd.concat([df_X_ohlc, \n",
    "                          df_y], \n",
    "                         axis=1, \n",
    "                         ignore_index=True)  \n",
    "df_OHLC.columns = list(df_X_ohlc) + list(df_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Add the rectangle_here columns back on \n",
    "df_OHLC_ = pd.concat([pd.DataFrame(df_ohlc_and_rectangles['rectangle_here']).reset_index(drop=True), \n",
    "                          df_OHLC], \n",
    "                         axis=1, \n",
    "                         ignore_index=True)  \n",
    "df_OHLC_.columns = list(pd.DataFrame(df_ohlc_and_rectangles['rectangle_here'])) + list(df_OHLC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def proximal_distal_match_invert(df):\n",
    "    \n",
    "    # Set all Supply/Demand row to nans to start clean\n",
    "    df['Proximal_discrete_value'] = np.nan\n",
    "    df['Distal_discrete_value'] = np.nan\n",
    "    \n",
    "    # Create list of all zones, filtered by if there's a potential zone in the row\n",
    "    potential_zone = df[df.rectangle_here.isnull() == False]\n",
    "    \n",
    "    # Create list of the indices of the zones\n",
    "    potential_zone_indices = potential_zone.index.tolist()\n",
    "            \n",
    "    labels_distal = [col for col in list(df) if col.startswith('Distal')]\n",
    "    labels_proximal = [col for col in list(df) if col.startswith('Proximal')]\n",
    "    \n",
    "    # For each zone\n",
    "    for idx in potential_zone_indices:\n",
    "        #print(\"Processing index: \", idx)\n",
    "        # If current iterable index + 1 is > len (e.g. if we are at the end of the DF)\n",
    "        if idx+1 > len(df):\n",
    "\n",
    "            # Quit the loop\n",
    "            break\n",
    "        \n",
    "            \n",
    "        for distal_match_col in labels_distal:\n",
    "            #print(df.iloc[idx][distal_match_col])\n",
    "            #print(distal_match_col)\n",
    "            if df.ix[idx, distal_match_col] == True:\n",
    "                lag_col_match = \"lag_\" + distal_match_col[13:]\n",
    "                #print('Lag col match is:', lag_col_match)\n",
    "                #print('The value contained at idx/lag_col_match: ', idx, \", \", df.iloc[idx][lag_col_match])\n",
    "                #print('The value at idx/distal_discrete_value: ', idx, \", \", df.iloc[idx]['Distal_discrete_value'])\n",
    "                distal_discrete_value = df.iloc[idx][lag_col_match]\n",
    "                df.ix[idx, 'Distal_discrete_value'] = distal_discrete_value\n",
    "                #print('The value at idx/distal_discrete_value: ', idx, \", \", df.iloc[idx]['Distal_discrete_value'])\n",
    "    \n",
    "        for proximal_match_col in labels_proximal:\n",
    "            #print(df.iloc[idx][distal_match_col])\n",
    "            #print(distal_match_col)\n",
    "            if df.ix[idx, proximal_match_col] == True:\n",
    "                lag_col_match = \"lag_\" + proximal_match_col[15:]\n",
    "                #print('Lag col match is:', lag_col_match)\n",
    "                #print('The value contained at idx/lag_col_match: ', idx, \", \", df.iloc[idx][lag_col_match])\n",
    "                #print('The value at idx/proximal_discrete_value: ', idx, \", \", df.iloc[idx]['Proximal_discrete_value'])\n",
    "                proximal_discrete_value = df.iloc[idx][lag_col_match]\n",
    "                df.ix[idx, 'Proximal_discrete_value'] = proximal_discrete_value\n",
    "                #print('The value at idx/proximal_discrete_value: ', idx, \", \", df.iloc[idx]['Proximal_discrete_value'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "proximal_distal_match_invert(df_OHLC_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "list(df_ohlc_and_rectangles)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize preds and OHLC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import zigzag as zigzag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ohlc_data_col_list = ['O',\n",
    " 'H',\n",
    " 'L',\n",
    " 'C',\n",
    " 'V',\n",
    " 'Proximal_discrete_value',\n",
    " 'Distal_discrete_value']\n",
    "\n",
    "df_ohlc_and_rectangles_col_list = ['Epoch Date',\n",
    " 'Supply/Demand',\n",
    " 'Epoch Date Start',\n",
    " 'Epoch Date End',]\n",
    "\n",
    "new_ohlc_data_col_list = ['O',\n",
    " 'H',\n",
    " 'L',\n",
    " 'C',\n",
    " 'V',\n",
    " 'Proximal',\n",
    " 'Distal']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Add the rectangle_here columns back on \n",
    "df_ohlc_data = pd.concat([df_OHLC_[ohlc_data_col_list], \n",
    "                          df_ohlc_and_rectangles[df_ohlc_and_rectangles_col_list]], \n",
    "                         axis=1, \n",
    "                         ignore_index=True)\n",
    "\n",
    "df_ohlc_data.columns = new_ohlc_data_col_list + df_ohlc_and_rectangles_col_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_ohlc_data['Epoch Date End'] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_processing.zone_ender(df_ohlc_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_processing.supply_or_demand(df_ohlc_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def viz_ohlc(df):    \n",
    "    # Convert Dates to datetime\n",
    "    df[\"Epoch Date\"] = pd.to_datetime(df[\"Epoch Date\"], unit='s')\n",
    "    df[\"Epoch Date Start\"] = pd.to_datetime(df[\"Epoch Date Start\"], unit='s')\n",
    "    df[\"Epoch Date End\"] = pd.to_datetime(df[\"Epoch Date End\"], unit='s')\n",
    "\n",
    "    w = 12*60*60*1000 # half day in ms\n",
    "\n",
    "    TOOLS = \"pan,xwheel_zoom,wheel_zoom,box_zoom,reset,save\"\n",
    "    p = figure(x_axis_type=\"datetime\", tools=TOOLS, plot_height=500, \n",
    "               plot_width=1200, title=\"🍩\", active_scroll='xwheel_zoom')\n",
    "    p.xaxis.major_label_orientation = pi/4\n",
    "    p.grid.grid_line_alpha=0.5\n",
    "\n",
    "    p.segment(df['Epoch Date'], df.H, df['Epoch Date'], df.L, color=\"black\")\n",
    "    p.vbar(df['Epoch Date'], w, df.O, df.C)\n",
    "\n",
    "    # Add Rectangle data\n",
    "    df_sp = df.dropna(subset=['Supply/Demand'])\n",
    "\n",
    "    source_supply = ColumnDataSource(df_sp.loc[df_sp['Supply/Demand']=='SUPPLY', :])\n",
    "    rect_supply = Quad(left=\"Epoch Date Start\", top=\"Proximal\", right=\"Epoch Date End\", bottom=\"Distal\", fill_color=\"firebrick\", line_alpha=0.2, fill_alpha=0.2) \n",
    "    p.add_glyph(source_supply, rect_supply)\n",
    "\n",
    "    source_demand = ColumnDataSource(df_sp.loc[df_sp['Supply/Demand']=='DEMAND', :])\n",
    "    rect_demand = Quad(left=\"Epoch Date Start\", top=\"Proximal\", right=\"Epoch Date End\", bottom=\"Distal\", fill_color=\"steelblue\", line_alpha=0.2, fill_alpha=0.2)\n",
    "    p.add_glyph(source_demand, rect_demand)\n",
    "\n",
    "\n",
    "    output_file(\"candlestick.html\", title=\"candlestick data\")\n",
    "    show(p)  # open a browser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "viz_ohlc(df_ohlc_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
